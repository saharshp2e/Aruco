{"ast":null,"code":"var _jsxFileName = \"/home/user/Documents/Aruco_POC/aruco-detector/src/CameraFeed.js\",\n  _s = $RefreshSig$();\n// import React, { useEffect, useRef, useState } from 'react';\n// import axios from 'axios';\n\n// const CameraFeed = () => {\n//   const [detected, setDetected] = useState(false);\n//   const [completed, setCompleted] = useState(false);\n//   const [currentStep, setCurrentStep] = useState(0);  // Track the current step\n//   const [isTutorialStarted, setIsTutorialStarted] = useState(false); // Track whether tutorial has started\n//   const [isAudioPlaying, setIsAudioPlaying] = useState(false);\n//   const videoRef = useRef(null);\n//   const canvasRef = useRef(null);\n//   const audioRefs = useRef([\n//     new Audio('/voice1.mp3'), // Step 1: Introduction to sulfate test\n//     new Audio('/voice2.mp3'), // Step 2: Show distilled water\n//     new Audio('/voice3.mp3'), // Step 3: Show test tube 1\n//     new Audio('/voice4.mp3'),\n//     new Audio('/voice5.mp3'),\n//     new Audio('/voice6.mp3'),\n//     new Audio('/voice7.mp3'),\n//     new Audio('/voice8.mp3'),\n//     new Audio('/voice9.mp3'),\n//     new Audio('/voice10.mp3'),\n//     new Audio('/voice11.mp3'),\n//     new Audio('/voice12.mp3'),\n//     new Audio('/voice13.mp3'), // Step 13: Test completion message\n//   ]);\n\n//   // Start camera feed and process frames only when the tutorial is started\n//   useEffect(() => {\n//     if (isTutorialStarted) {\n//       const video = videoRef.current;\n\n//       // Web camera initialization logic\n//       navigator.mediaDevices.getUserMedia({ video: true })\n//         .then((stream) => {\n//           video.srcObject = stream;\n//           video.onloadedmetadata = () => {\n//             video.play();\n//           };\n//         })\n//         .catch(err => console.error(\"Error accessing webcam:\", err));\n\n//       // Clean up: stop the camera stream when component unmounts\n//       return () => {\n//         if (video.srcObject) {\n//           video.srcObject.getTracks().forEach(track => track.stop());\n//         }\n//       };\n//     }\n//   }, [isTutorialStarted]);  // Only run this effect when the tutorial starts\n\n//   const processFrame = async () => {\n//     if (!isTutorialStarted || completed) return;  // Stop processing if the tutorial hasn't started or test is complete\n\n//     const canvas = canvasRef.current;\n//     const context = canvas.getContext('2d');\n\n//     // Ensure video is ready and draw the video feed onto the canvas\n//     const video = videoRef.current;\n//     if (video.readyState === video.HAVE_ENOUGH_DATA) {\n//       context.drawImage(video, 0, 0, canvas.width, canvas.height);\n\n//       // Send frame to backend for ArUco detection\n//       canvas.toBlob(async (blob) => {\n//         const formData = new FormData();\n//         formData.append('image', blob, 'frame.jpg');\n//         try {\n//           const response = await axios.post('http://localhost:5000/detect', formData, { responseType: 'json' });\n//           // console.log(\"Response from backend:\", response.data);  // Log response\n\n//           const { detected, augmented_image, ids, currentStep } = response.data;  // Destructure response\n\n//           if (ids) {\n//               handleMarkerDetection(ids, currentStep);\n//             }\n\n//           // Clear the canvas before drawing the new image\n//           context.clearRect(0, 0, canvas.width, canvas.height);\n\n//           // Display processed frame (augmented) coming from backend\n//           const img = new Image();\n//           img.src = `data:image/jpeg;base64,${augmented_image}`;\n//           img.onload = () => {\n//             context.drawImage(img, 0, 0, canvas.width, canvas.height);\n//           };\n//         } catch (err) {\n//           console.error(\"Error processing frame:\", err);\n//         }\n//       }, 'image/jpeg');\n//     }\n//   };\n\n//   const handleMarkerDetection = (ids,currentStepFromBackend) => {\n//     if (completed) return;\n//     // console.log('inside handleMarkerDetection');\n//      // Stop if completed\n\n//         // For step 5, ensure both IDs 1 and 3 are present\n//     if (currentStep === 5 && ids.includes(1) && ids.includes(3)) {\n//       console.log('Step 5: Detected both Marker 1 and Marker 3');\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     if (currentStep === 6 && ids.includes(0) && ids.includes(1)) {\n//       console.log('Step 6: Detected both Marker 0 and Marker 1');\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 7: Detect marker ID=1 with alternating y-axis conditions\n//     if (currentStep === 7 && ids.includes(1) && !ids.includes(0)) {\n//       console.log('Step 7: Marker 1 detected, alternating y-axis required');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 8: Detect marker ID=1 with alternating y-axis conditions\n//     if (currentStep === 8 && ids.includes(1) && ids.includes(2)) {\n//       console.log('Step 8: Detected both Marker 1 and Marker 2');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 9: Detect marker ID=1 and marker ID=3\n//     if (currentStep === 9 && ids.includes(1) && ids.includes(3)) {\n//       console.log('Step 9: Detected both Marker 1 and Marker 3');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 10: Detect marker ID=1 and marker ID=4\n//     if (currentStep === 10 && ids.includes(1) && ids.includes(4)) {\n//       console.log('Step 10: Detected both Marker 1 and Marker 4');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     const expectedMarkerId = currentStep; // Expect the next marker ID\n//     // console.log('expectedMarkerId: '+expectedMarkerId+',currentSTep: '+currentStep)\n\n//     if (ids.includes(expectedMarkerId)) {\n//       console.log(`Step ${expectedMarkerId} verified with marker ID: ${expectedMarkerId}`);\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//     }\n//   };\n\n//   const playNextAudio = () => {\n//     if (currentStep + 2 >= audioRefs.current.length) return; // Prevent out-of-bounds\n\n//     const currentAudio = audioRefs.current[currentStep + 2];\n\n//     setIsAudioPlaying(true); // Set audio playing to true\n//     currentAudio.play().catch(err => console.error(\"Audio play error:\", err));\n\n//     currentAudio.onended = () => {\n//       setIsAudioPlaying(false); // Set audio playing to false after it finishes\n\n//       // Check if this is the last instructional step\n//       if (currentStep === audioRefs.current.length - 2) {\n//         setCompleted(true);\n//         audioRefs.current[audioRefs.current.length - 1].play().catch(err => console.error(\"Audio play error:\", err)); // Play completion audio\n//       }\n//     };\n//   };\n\n//   // Trigger the frame processing when the tutorial starts\n//   useEffect(() => {\n//     if (isTutorialStarted) {\n//       const interval = setInterval(processFrame, 1000 / 10);  // 10 FPS\n//       return () => clearInterval(interval);\n//     }\n//   }, [isTutorialStarted, currentStep]);\n\n//   const startTutorial = () => {\n//     setIsTutorialStarted(true);\n//     audioRefs.current[0].play().catch(err => console.error(\"Audio play error:\", err));\n//     audioRefs.current[0].onended = () => {\n//       audioRefs.current[1].play().catch(err => console.error(\"Audio play error:\", err));\n//     };\n//     setCurrentStep(0);\n//   };\n\n//   return (\n//     <div>\n//       {!isTutorialStarted && (\n//         <button onClick={startTutorial}>Start Tutorial</button>\n//       )}\n//       {isTutorialStarted && (\n//         <div>\n//           <video ref={videoRef} style={{ display: 'none' }} />\n//           <canvas ref={canvasRef} width=\"640\" height=\"480\" style={{ border: '1px solid black' }} />\n//           {completed && <p style={{ color: 'blue', marginTop: '10px' }}>Sulfate Ion Test Completed</p>}\n//         </div>\n//       )}\n//     </div>\n//   );\n// };\n\n// export default CameraFeed;\n\nimport React, { useEffect, useRef, useState } from 'react';\nimport axios from 'axios';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst CameraFeed = () => {\n  _s();\n  const [detected, setDetected] = useState(false);\n  const [completed, setCompleted] = useState(false);\n  const [currentStep, setCurrentStep] = useState(0); // Track the current step\n  const [isTutorialStarted, setIsTutorialStarted] = useState(false); // Track whether tutorial has started\n  const [isAudioPlaying, setIsAudioPlaying] = useState(false); // Track if audio is playing\n  const [conditionsMetTime, setConditionsMetTime] = useState(null); // Track when conditions were met\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  const processedCanvasRef = useRef(null);\n  const overlayCanvasRef = useRef(null); // Overlay canvas for text and y-axis\n  const audioRefs = useRef([new Audio('/voice1.mp3'),\n  // Step 1: Introduction to sulfate test\n  new Audio('/voice2.mp3'),\n  // Step 2: Show distilled water\n  new Audio('/voice3.mp3'),\n  // Step 3: Show test tube 1\n  new Audio('/voice4.mp3'), new Audio('/voice5.mp3'), new Audio('/voice6.mp3'), new Audio('/voice7.mp3'), new Audio('/voice8.mp3'), new Audio('/voice9.mp3'), new Audio('/voice10.mp3'), new Audio('/voice11.mp3'), new Audio('/voice12.mp3'),\n  // Add the rest of the steps here\n  new Audio('/voice13.mp3') // Step 13: Test completion message\n  ]);\n\n  // Paragraphs for each step\n  const stepParagraphs = {\n    '-1': 'आज हम सल्फेट आयनों की पहचान के लिए एक सरल रसायन परीक्षण करेंगे। पहले, हम यह सुनिश्चित कर लेते हैं कि हमारे पास सभी आवश्यक उपकरण तैयार हैं। डिस्टिल्ड वाटर का कंटेनर दिखाएँ।',\n    0: 'टेस्ट ट्यूब 1 दिखाएँ।',\n    1: 'हाइड्रोक्लोरिक एसिड का कंटेनर दिखाएँ।',\n    2: 'बैरियम नाइट्रेट का कंटेनर दिखाएँ।',\n    3: 'सल्फ्यूरिक एसिड का कंटेनर दिखाएँ।',\n    4: 'अब हम सॉल्ट सोल्यूशन तैयार करेंगे। बैरियम नाइट्रेट सॉल्ट को टेस्ट ट्यूब 1 में डालें।',\n    5: 'डिस्टिल्ड वाटर को टेस्ट ट्यूब 1 में डालें।',\n    6: 'टेस्ट ट्यूब को जोर से हिलाएँ जब तक कि कम से कम आधा सॉल्ट घुल न जाए। कैमरे के सामने टेस्ट ट्यूब को साइडवेज़ में घुमाएँ ताकि इस स्टेप का पूरा होना संकेतित हो सके।',\n    7: 'अब हम प्रारंभिक परीक्षण करेंगे। हाइड्रोक्लोरिक एसिड से यह सुनिश्चित होता है कि सोल्यूशन में कोई कार्बोनेट आयन या अन्य बाधक पदार्थ न हो। अगर कोई प्रतिक्रिया (बुलबुले या गैस) नहीं होती, तो सल्फेट परीक्षण करें। अब टेस्ट ट्यूब 1 में सोल्यूशन में डायलूट हाइड्रोक्लोरिक एसिड की कुछ बूंदें डालें।',\n    8: 'अब हम सल्फेट परीक्षण करेंगे। टेस्ट ट्यूब 1 में सोल्यूशन में कुछ बूंदें बैरियम नाइट्रेट की डालें। अगर सफ़ेद प्रेसिपिटेट बनता है, तो इसका मतलब है कि सैंपल में सल्फेट आयन मौजूद हैं। बैरियम सल्फेट घुलनशील नहीं होता है और सल्फेट आयन की उपस्थिति में सफ़ेद प्रेसिपिटेट बनाता है।',\n    9: 'अब हम पुष्टिकारी परीक्षण करेंगे। यह सुनिश्चित करने के लिए कि बना हुआ प्रेसिपिटेट बैरियम सल्फेट ही है, न कि कोई अन्य यौगिक। अगर कोई अतिरिक्त प्रेसिपिटेट नहीं बनता है, तो सल्फेट आयन की पुष्टि हो जाती है। अब टेस्ट ट्यूब 1 में, जो बैरियम सल्फेट का सोल्यूशन है, उसमें कुछ बूंदें सल्फ्यूरिक एसिड की डालें।',\n    10: 'बधाई हो, सल्फेट आयन परीक्षण पूरा हुआ।'\n  };\n  const MIN_CONDITION_DURATION = 2000; // 2 seconds in milliseconds\n\n  // Start camera feed and process frames only when the tutorial is started\n  useEffect(() => {\n    if (isTutorialStarted) {\n      const video = videoRef.current;\n\n      // Web camera initialization logic\n      navigator.mediaDevices.getUserMedia({\n        video: true\n      }).then(stream => {\n        video.srcObject = stream;\n        video.onloadedmetadata = () => {\n          video.play();\n        };\n      }).catch(err => console.error(\"Error accessing webcam:\", err));\n\n      // Clean up: stop the camera stream when component unmounts\n      return () => {\n        if (video.srcObject) {\n          video.srcObject.getTracks().forEach(track => track.stop());\n        }\n      };\n    }\n  }, [isTutorialStarted]); // Only run this effect when the tutorial starts\n\n  // const processFrame = async () => {\n  //   if (!isTutorialStarted || completed || isAudioPlaying) return; // Stop processing if tutorial hasn't started, is completed, or audio is playing\n\n  //   const canvas = canvasRef.current;\n  //   const context = canvas.getContext('2d');\n\n  //   // Ensure video is ready and draw the video feed onto the canvas\n  //   const video = videoRef.current;\n  //   if (video.readyState === video.HAVE_ENOUGH_DATA) {\n  //     context.drawImage(video, 0, 0, canvas.width, canvas.height); // Draw live feed\n\n  //     // Send frame to backend for ArUco detection\n  //     canvas.toBlob(async (blob) => {\n  //       const formData = new FormData();\n  //       formData.append('image', blob, 'frame.jpg');\n  //       try {\n  //         const response = await axios.post('http://localhost:5000/detect', formData, { responseType: 'json' });\n  //         // console.log(\"Response from backend:\", response.data);  // Log response\n\n  //         const { detected, augmented_image, ids, currentStep } = response.data; // Destructure response\n\n  //         if (ids) {\n  //           handleMarkerDetection(ids, currentStep);\n  //         }\n\n  //         // Clear the canvas before drawing the new image\n  //         context.clearRect(0, 0, canvas.width, canvas.height);\n\n  //         // Display processed frame (augmented) coming from backend\n  //         const img = new Image();\n  //         img.src = `data:image/jpeg;base64,${augmented_image}`;\n  //         img.onload = () => {\n  //           context.drawImage(img, 0, 0, canvas.width, canvas.height);\n  //         };\n  //       } catch (err) {\n  //         console.error(\"Error processing frame:\", err);\n  //       }\n  //     }, 'image/jpeg');\n  //   }\n  // };\n\n  const processFrame = async () => {\n    if (!isTutorialStarted || completed || isAudioPlaying) return;\n    const canvas = canvasRef.current;\n    const context = canvas.getContext('2d');\n\n    // Create an offscreen canvas for double buffering\n    const offscreenCanvas = document.createElement('canvas');\n    const offscreenContext = offscreenCanvas.getContext('2d');\n    offscreenCanvas.width = canvas.width;\n    offscreenCanvas.height = canvas.height;\n\n    // Ensure the video is ready and draw the video feed onto the offscreen canvas\n    const video = videoRef.current;\n    if (video.readyState === video.HAVE_ENOUGH_DATA) {\n      offscreenContext.drawImage(video, 0, 0, offscreenCanvas.width, offscreenCanvas.height);\n\n      // Send frame to backend for ArUco detection\n      offscreenCanvas.toBlob(async blob => {\n        const formData = new FormData();\n        formData.append('image', blob, 'frame.jpg');\n        try {\n          const response = await axios.post('http://localhost:5000/detect', formData, {\n            responseType: 'json'\n          });\n          const {\n            detected,\n            augmented_image,\n            ids,\n            currentStep,\n            roll\n          } = response.data;\n          if (ids) {\n            handleMarkerDetection(ids, roll);\n          }\n\n          // Load the augmented image (processed frame from backend)\n          const img = new Image();\n          img.src = `data:image/jpeg;base64,${augmented_image}`;\n          img.onload = () => {\n            // Draw the augmented image on the offscreen canvas\n            offscreenContext.drawImage(img, 0, 0, offscreenCanvas.width, offscreenCanvas.height);\n\n            // Now copy the entire offscreen canvas to the visible canvas in one step\n            context.clearRect(0, 0, canvas.width, canvas.height); // Clear the main canvas\n            context.drawImage(offscreenCanvas, 0, 0, canvas.width, canvas.height);\n          };\n        } catch (err) {\n          console.error(\"Error processing frame:\", err);\n        }\n      }, 'image/jpeg');\n    }\n  };\n  const handleMarkerDetection = (ids, roll) => {\n    if (completed) return;\n    // Stop if completed\n\n    const now = new Date().getTime();\n\n    // For step 5, ensure both IDs 1 and 3 are present\n    if (currentStep === 5 && ids.includes(1) && ids.includes(3)) {\n      const roll1 = roll[1];\n      const roll3 = roll[3];\n      if (roll3 > 3 && roll1 < 10) {\n        console.log('Step 5: Detected both Marker 1 and Marker 3');\n        setCurrentStep(currentStep + 1);\n        playNextAudio();\n        return;\n      }\n    }\n    if (currentStep === 6 && ids.includes(0) && ids.includes(1)) {\n      const roll0 = roll[0];\n      const roll1 = roll[1];\n      if (roll0 < 3 && roll1 < 3) {\n        console.log('Step 6: Detected both Marker 0 and Marker 1');\n        setCurrentStep(currentStep + 1);\n        playNextAudio();\n        return;\n      }\n    }\n\n    // // Step 7: Detect marker ID=1 with alternating y-axis conditions\n    // if (currentStep === 7 && ids.includes(1) && !ids.includes(0)) {\n    //   const roll1 = roll[1];\n    //   let bool1= false\n    //   let bool2= false\n    //   if (roll1 > 3) {\n    //     bool1 = true\n    //   }\n    //   else if (roll1 < 3) {\n    //     bool2 = true\n    //   }\n    //   if (bool1 && bool2) {\n    //     console.log('Step 7: Marker 1 detected, alternating y-axis required');\n    //     // Assume the backend sends this information via the currentStepFromBackend\n    //     setCurrentStep(currentStep + 1);\n    //     playNextAudio();\n    //     return;\n    //   }\n\n    // }\n\n    // Ensure these are defined outside the function to persist between calls\n    let previousConditionWasPositive = null; // null initially, tracks the last condition (positive/negative)\n    let alternationCounter = 0; // Tracks number of alternations\n\n    function detectMarkerAndAlternate() {\n      if (currentStep === 7 && ids.includes(1) && !ids.includes(0)) {\n        const roll1 = roll[1]; // Assume roll1 is the value we're checking for alternation\n        let conditionMet = false;\n        console.log(`Roll1 value: ${roll1}, Previous condition: ${previousConditionWasPositive}, Alternation Counter: ${alternationCounter}`);\n\n        // If roll1 is positive and the last condition was negative (or null for the first positive check)\n        if (roll1 > 0 && (previousConditionWasPositive === false || previousConditionWasPositive === null)) {\n          previousConditionWasPositive = true; // Update to positive\n          conditionMet = true;\n          console.log(\"Roll1 is positive and previous was negative or null\");\n        }\n        // If roll1 is negative and the last condition was positive\n        else if (roll1 < 0 && previousConditionWasPositive === true) {\n          previousConditionWasPositive = false; // Update to negative\n          conditionMet = true;\n          console.log(\"Roll1 is negative and previous was positive\");\n        }\n\n        // Only increment the counter if an alternation occurred\n        if (conditionMet) {\n          alternationCounter++;\n          console.log(`Alternation detected, Counter: ${alternationCounter}`);\n\n          // Check if we've completed two full alternations (positive → negative → positive)\n          if (alternationCounter >= 2) {\n            console.log('Step 7: Two alternations completed, proceeding to the next step.');\n            setCurrentStep(currentStep + 1);\n            playNextAudio();\n\n            // Reset variables after completion\n            alternationCounter = 0;\n            previousConditionWasPositive = null;\n            return;\n          } else {\n            console.log(`Step 7: Alternation ${alternationCounter} completed, waiting for more alternations.`);\n          }\n        }\n      }\n    }\n\n    // Step 8: Detect marker ID=1 with alternating y-axis conditions\n    if (currentStep === 8 && ids.includes(1) && ids.includes(2)) {\n      const roll1 = roll[1];\n      const roll2 = roll[2];\n      if (roll1 < 3 && roll2 > 3) {\n        console.log('Step 8: Detected both Marker 1 and Marker 2');\n        // Assume the backend sends this information via the currentStepFromBackend\n        setCurrentStep(currentStep + 1);\n        playNextAudio();\n        return;\n      }\n    }\n\n    // Step 9: Detect marker ID=1 and marker ID=3\n    if (currentStep === 9 && ids.includes(1) && ids.includes(3)) {\n      const roll1 = roll[1];\n      const roll3 = roll[3];\n      if (roll1 > 3 && roll3 < 3) {\n        console.log('Step 9: Detected both Marker 1 and Marker 3');\n        // Assume the backend sends this information via the currentStepFromBackend\n        setCurrentStep(currentStep + 1);\n        playNextAudio();\n        return;\n      }\n    }\n\n    // Step 10: Detect marker ID=1 and marker ID=4\n    if (currentStep === 10 && ids.includes(1) && ids.includes(4)) {\n      const roll1 = roll[1];\n      const roll4 = roll[4];\n      if (roll1 < 3 && roll4 > 3) {\n        console.log('Step 10: Detected both Marker 1 and Marker 4');\n        // Assume the backend sends this information via the currentStepFromBackend\n        setCurrentStep(currentStep + 1);\n        playNextAudio();\n        return;\n      }\n    }\n    const expectedMarkerId = currentStep; // Expect the next marker ID\n\n    if (ids.includes(expectedMarkerId)) {\n      console.log(`Step ${expectedMarkerId} verified with marker ID: ${expectedMarkerId}`);\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n    }\n  };\n  const playNextAudio = () => {\n    if (currentStep + 2 >= audioRefs.current.length) return; // Prevent out-of-bounds\n\n    const currentAudio = audioRefs.current[currentStep + 2];\n    setIsAudioPlaying(true); // Set audio playing to true\n    currentAudio.play().catch(err => console.error(\"Audio play error:\", err));\n    currentAudio.onended = () => {\n      setIsAudioPlaying(false); // Set audio playing to false after it finishes\n\n      // Check if this is the last instructional step\n      if (currentStep === audioRefs.current.length - 2) {\n        setCompleted(true);\n        audioRefs.current[audioRefs.current.length - 1].play().catch(err => console.error(\"Audio play error:\", err)); // Play completion audio\n      }\n    };\n  };\n\n  // Trigger the frame processing when the tutorial starts\n  useEffect(() => {\n    if (isTutorialStarted) {\n      const interval = setInterval(processFrame, 1000 / 10); // 10 FPS\n      return () => clearInterval(interval);\n    }\n  }, [isTutorialStarted, currentStep, isAudioPlaying]); // Added isAudioPlaying to the dependency array\n\n  const startTutorial = () => {\n    setIsTutorialStarted(true);\n    audioRefs.current[0].play().catch(err => console.error(\"Audio play error:\", err));\n    audioRefs.current[0].onended = () => {\n      audioRefs.current[1].play().catch(err => console.error(\"Audio play error:\", err));\n    };\n    setCurrentStep(0);\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [!isTutorialStarted && /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: startTutorial,\n      children: \"Start Tutorial\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 580,\n      columnNumber: 9\n    }, this), isTutorialStarted && /*#__PURE__*/_jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"video\", {\n        ref: videoRef,\n        style: {\n          display: 'none'\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 584,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n        ref: canvasRef,\n        width: \"640\",\n        height: \"480\",\n        style: {\n          border: '1px solid black'\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 585,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        style: {\n          marginTop: '10px'\n        },\n        children: stepParagraphs[currentStep - 1] || 'Loading...'\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 586,\n        columnNumber: 11\n      }, this), completed && /*#__PURE__*/_jsxDEV(\"p\", {\n        style: {\n          color: 'blue',\n          marginTop: '10px'\n        },\n        children: \"Sulfate Ion Test Completed\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 589,\n        columnNumber: 25\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 583,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 578,\n    columnNumber: 5\n  }, this);\n};\n_s(CameraFeed, \"69zvIXqOWATJob/1RfHRaEKeYmk=\");\n_c = CameraFeed;\nexport default CameraFeed;\nvar _c;\n$RefreshReg$(_c, \"CameraFeed\");","map":{"version":3,"names":["React","useEffect","useRef","useState","axios","jsxDEV","_jsxDEV","CameraFeed","_s","detected","setDetected","completed","setCompleted","currentStep","setCurrentStep","isTutorialStarted","setIsTutorialStarted","isAudioPlaying","setIsAudioPlaying","conditionsMetTime","setConditionsMetTime","videoRef","canvasRef","processedCanvasRef","overlayCanvasRef","audioRefs","Audio","stepParagraphs","MIN_CONDITION_DURATION","video","current","navigator","mediaDevices","getUserMedia","then","stream","srcObject","onloadedmetadata","play","catch","err","console","error","getTracks","forEach","track","stop","processFrame","canvas","context","getContext","offscreenCanvas","document","createElement","offscreenContext","width","height","readyState","HAVE_ENOUGH_DATA","drawImage","toBlob","blob","formData","FormData","append","response","post","responseType","augmented_image","ids","roll","data","handleMarkerDetection","img","Image","src","onload","clearRect","now","Date","getTime","includes","roll1","roll3","log","playNextAudio","roll0","previousConditionWasPositive","alternationCounter","detectMarkerAndAlternate","conditionMet","roll2","roll4","expectedMarkerId","length","currentAudio","onended","interval","setInterval","clearInterval","startTutorial","children","onClick","fileName","_jsxFileName","lineNumber","columnNumber","ref","style","display","border","marginTop","color","_c","$RefreshReg$"],"sources":["/home/user/Documents/Aruco_POC/aruco-detector/src/CameraFeed.js"],"sourcesContent":["\n// import React, { useEffect, useRef, useState } from 'react';\n// import axios from 'axios';\n\n// const CameraFeed = () => {\n//   const [detected, setDetected] = useState(false);\n//   const [completed, setCompleted] = useState(false);\n//   const [currentStep, setCurrentStep] = useState(0);  // Track the current step\n//   const [isTutorialStarted, setIsTutorialStarted] = useState(false); // Track whether tutorial has started\n//   const [isAudioPlaying, setIsAudioPlaying] = useState(false);\n//   const videoRef = useRef(null);\n//   const canvasRef = useRef(null);\n//   const audioRefs = useRef([\n//     new Audio('/voice1.mp3'), // Step 1: Introduction to sulfate test\n//     new Audio('/voice2.mp3'), // Step 2: Show distilled water\n//     new Audio('/voice3.mp3'), // Step 3: Show test tube 1\n//     new Audio('/voice4.mp3'),\n//     new Audio('/voice5.mp3'),\n//     new Audio('/voice6.mp3'),\n//     new Audio('/voice7.mp3'),\n//     new Audio('/voice8.mp3'),\n//     new Audio('/voice9.mp3'),\n//     new Audio('/voice10.mp3'),\n//     new Audio('/voice11.mp3'),\n//     new Audio('/voice12.mp3'),\n//     new Audio('/voice13.mp3'), // Step 13: Test completion message\n//   ]);\n\n//   // Start camera feed and process frames only when the tutorial is started\n//   useEffect(() => {\n//     if (isTutorialStarted) {\n//       const video = videoRef.current;\n\n//       // Web camera initialization logic\n//       navigator.mediaDevices.getUserMedia({ video: true })\n//         .then((stream) => {\n//           video.srcObject = stream;\n//           video.onloadedmetadata = () => {\n//             video.play();\n//           };\n//         })\n//         .catch(err => console.error(\"Error accessing webcam:\", err));\n\n//       // Clean up: stop the camera stream when component unmounts\n//       return () => {\n//         if (video.srcObject) {\n//           video.srcObject.getTracks().forEach(track => track.stop());\n//         }\n//       };\n//     }\n//   }, [isTutorialStarted]);  // Only run this effect when the tutorial starts\n\n//   const processFrame = async () => {\n//     if (!isTutorialStarted || completed) return;  // Stop processing if the tutorial hasn't started or test is complete\n  \n//     const canvas = canvasRef.current;\n//     const context = canvas.getContext('2d');\n    \n//     // Ensure video is ready and draw the video feed onto the canvas\n//     const video = videoRef.current;\n//     if (video.readyState === video.HAVE_ENOUGH_DATA) {\n//       context.drawImage(video, 0, 0, canvas.width, canvas.height);\n  \n//       // Send frame to backend for ArUco detection\n//       canvas.toBlob(async (blob) => {\n//         const formData = new FormData();\n//         formData.append('image', blob, 'frame.jpg');\n//         try {\n//           const response = await axios.post('http://localhost:5000/detect', formData, { responseType: 'json' });\n//           // console.log(\"Response from backend:\", response.data);  // Log response\n  \n//           const { detected, augmented_image, ids, currentStep } = response.data;  // Destructure response\n          \n//           if (ids) {\n//               handleMarkerDetection(ids, currentStep);\n//             }\n\n//           // Clear the canvas before drawing the new image\n//           context.clearRect(0, 0, canvas.width, canvas.height);\n  \n//           // Display processed frame (augmented) coming from backend\n//           const img = new Image();\n//           img.src = `data:image/jpeg;base64,${augmented_image}`;\n//           img.onload = () => {\n//             context.drawImage(img, 0, 0, canvas.width, canvas.height);\n//           };\n//         } catch (err) {\n//           console.error(\"Error processing frame:\", err);\n//         }\n//       }, 'image/jpeg');\n//     }\n//   };\n\n\n\n//   const handleMarkerDetection = (ids,currentStepFromBackend) => {\n//     if (completed) return;\n//     // console.log('inside handleMarkerDetection');\n//      // Stop if completed\n\n\n//         // For step 5, ensure both IDs 1 and 3 are present\n//     if (currentStep === 5 && ids.includes(1) && ids.includes(3)) {\n//       console.log('Step 5: Detected both Marker 1 and Marker 3');\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     if (currentStep === 6 && ids.includes(0) && ids.includes(1)) {\n//       console.log('Step 6: Detected both Marker 0 and Marker 1');\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 7: Detect marker ID=1 with alternating y-axis conditions\n//     if (currentStep === 7 && ids.includes(1) && !ids.includes(0)) {\n//       console.log('Step 7: Marker 1 detected, alternating y-axis required');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 8: Detect marker ID=1 with alternating y-axis conditions\n//     if (currentStep === 8 && ids.includes(1) && ids.includes(2)) {\n//       console.log('Step 8: Detected both Marker 1 and Marker 2');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 9: Detect marker ID=1 and marker ID=3\n//     if (currentStep === 9 && ids.includes(1) && ids.includes(3)) {\n//       console.log('Step 9: Detected both Marker 1 and Marker 3');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 10: Detect marker ID=1 and marker ID=4\n//     if (currentStep === 10 && ids.includes(1) && ids.includes(4)) {\n//       console.log('Step 10: Detected both Marker 1 and Marker 4');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     const expectedMarkerId = currentStep; // Expect the next marker ID\n//     // console.log('expectedMarkerId: '+expectedMarkerId+',currentSTep: '+currentStep)\n\n//     if (ids.includes(expectedMarkerId)) {\n//       console.log(`Step ${expectedMarkerId} verified with marker ID: ${expectedMarkerId}`);\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//     }\n//   };\n\n//   const playNextAudio = () => {\n//     if (currentStep + 2 >= audioRefs.current.length) return; // Prevent out-of-bounds\n    \n    \n//     const currentAudio = audioRefs.current[currentStep + 2];\n\n    \n//     setIsAudioPlaying(true); // Set audio playing to true\n//     currentAudio.play().catch(err => console.error(\"Audio play error:\", err));\n    \n//     currentAudio.onended = () => {\n//       setIsAudioPlaying(false); // Set audio playing to false after it finishes\n  \n//       // Check if this is the last instructional step\n//       if (currentStep === audioRefs.current.length - 2) {\n//         setCompleted(true);\n//         audioRefs.current[audioRefs.current.length - 1].play().catch(err => console.error(\"Audio play error:\", err)); // Play completion audio\n//       }\n//     };\n//   };\n  \n  \n\n  \n//   // Trigger the frame processing when the tutorial starts\n//   useEffect(() => {\n//     if (isTutorialStarted) {\n//       const interval = setInterval(processFrame, 1000 / 10);  // 10 FPS\n//       return () => clearInterval(interval);\n//     }\n//   }, [isTutorialStarted, currentStep]);\n\n\n//   const startTutorial = () => {\n//     setIsTutorialStarted(true);\n//     audioRefs.current[0].play().catch(err => console.error(\"Audio play error:\", err));\n//     audioRefs.current[0].onended = () => {\n//       audioRefs.current[1].play().catch(err => console.error(\"Audio play error:\", err));\n//     };\n//     setCurrentStep(0);\n//   };\n  \n\n//   return (\n//     <div>\n//       {!isTutorialStarted && (\n//         <button onClick={startTutorial}>Start Tutorial</button>\n//       )}\n//       {isTutorialStarted && (\n//         <div>\n//           <video ref={videoRef} style={{ display: 'none' }} />\n//           <canvas ref={canvasRef} width=\"640\" height=\"480\" style={{ border: '1px solid black' }} />\n//           {completed && <p style={{ color: 'blue', marginTop: '10px' }}>Sulfate Ion Test Completed</p>}\n//         </div>\n//       )}\n//     </div>\n//   );\n// };\n\n// export default CameraFeed;\n\n\n\n\n\n\n\nimport React, { useEffect, useRef, useState } from 'react';\nimport axios from 'axios';\n\nconst CameraFeed = () => {\n  const [detected, setDetected] = useState(false);\n  const [completed, setCompleted] = useState(false);\n  const [currentStep, setCurrentStep] = useState(0); // Track the current step\n  const [isTutorialStarted, setIsTutorialStarted] = useState(false); // Track whether tutorial has started\n  const [isAudioPlaying, setIsAudioPlaying] = useState(false); // Track if audio is playing\n  const [conditionsMetTime, setConditionsMetTime] = useState(null); // Track when conditions were met\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  const processedCanvasRef = useRef(null);\n  const overlayCanvasRef = useRef(null); // Overlay canvas for text and y-axis\n  const audioRefs = useRef([\n    new Audio('/voice1.mp3'), // Step 1: Introduction to sulfate test\n    new Audio('/voice2.mp3'), // Step 2: Show distilled water\n    new Audio('/voice3.mp3'), // Step 3: Show test tube 1\n    new Audio('/voice4.mp3'),\n    new Audio('/voice5.mp3'),\n    new Audio('/voice6.mp3'),\n    new Audio('/voice7.mp3'),\n    new Audio('/voice8.mp3'),\n    new Audio('/voice9.mp3'),\n    new Audio('/voice10.mp3'),\n    new Audio('/voice11.mp3'),\n    new Audio('/voice12.mp3'),\n    // Add the rest of the steps here\n    new Audio('/voice13.mp3'), // Step 13: Test completion message\n  ]);\n\n    // Paragraphs for each step\n    const stepParagraphs = {\n      '-1': 'आज हम सल्फेट आयनों की पहचान के लिए एक सरल रसायन परीक्षण करेंगे। पहले, हम यह सुनिश्चित कर लेते हैं कि हमारे पास सभी आवश्यक उपकरण तैयार हैं। डिस्टिल्ड वाटर का कंटेनर दिखाएँ।',\n      0: 'टेस्ट ट्यूब 1 दिखाएँ।',\n      1: 'हाइड्रोक्लोरिक एसिड का कंटेनर दिखाएँ।',\n      2: 'बैरियम नाइट्रेट का कंटेनर दिखाएँ।',\n      3: 'सल्फ्यूरिक एसिड का कंटेनर दिखाएँ।',\n      4: 'अब हम सॉल्ट सोल्यूशन तैयार करेंगे। बैरियम नाइट्रेट सॉल्ट को टेस्ट ट्यूब 1 में डालें।',\n      5: 'डिस्टिल्ड वाटर को टेस्ट ट्यूब 1 में डालें।',\n      6: 'टेस्ट ट्यूब को जोर से हिलाएँ जब तक कि कम से कम आधा सॉल्ट घुल न जाए। कैमरे के सामने टेस्ट ट्यूब को साइडवेज़ में घुमाएँ ताकि इस स्टेप का पूरा होना संकेतित हो सके।',\n      7: 'अब हम प्रारंभिक परीक्षण करेंगे। हाइड्रोक्लोरिक एसिड से यह सुनिश्चित होता है कि सोल्यूशन में कोई कार्बोनेट आयन या अन्य बाधक पदार्थ न हो। अगर कोई प्रतिक्रिया (बुलबुले या गैस) नहीं होती, तो सल्फेट परीक्षण करें। अब टेस्ट ट्यूब 1 में सोल्यूशन में डायलूट हाइड्रोक्लोरिक एसिड की कुछ बूंदें डालें।',\n      8: 'अब हम सल्फेट परीक्षण करेंगे। टेस्ट ट्यूब 1 में सोल्यूशन में कुछ बूंदें बैरियम नाइट्रेट की डालें। अगर सफ़ेद प्रेसिपिटेट बनता है, तो इसका मतलब है कि सैंपल में सल्फेट आयन मौजूद हैं। बैरियम सल्फेट घुलनशील नहीं होता है और सल्फेट आयन की उपस्थिति में सफ़ेद प्रेसिपिटेट बनाता है।',\n      9: 'अब हम पुष्टिकारी परीक्षण करेंगे। यह सुनिश्चित करने के लिए कि बना हुआ प्रेसिपिटेट बैरियम सल्फेट ही है, न कि कोई अन्य यौगिक। अगर कोई अतिरिक्त प्रेसिपिटेट नहीं बनता है, तो सल्फेट आयन की पुष्टि हो जाती है। अब टेस्ट ट्यूब 1 में, जो बैरियम सल्फेट का सोल्यूशन है, उसमें कुछ बूंदें सल्फ्यूरिक एसिड की डालें।',\n      10: 'बधाई हो, सल्फेट आयन परीक्षण पूरा हुआ।'\n    };\n\n    const MIN_CONDITION_DURATION = 2000; // 2 seconds in milliseconds\n\n  // Start camera feed and process frames only when the tutorial is started\n  useEffect(() => {\n    if (isTutorialStarted) {\n      const video = videoRef.current;\n\n      // Web camera initialization logic\n      navigator.mediaDevices.getUserMedia({ video: true })\n        .then((stream) => {\n          video.srcObject = stream;\n          video.onloadedmetadata = () => {\n            video.play();\n          };\n        })\n        .catch(err => console.error(\"Error accessing webcam:\", err));\n\n      // Clean up: stop the camera stream when component unmounts\n      return () => {\n        if (video.srcObject) {\n          video.srcObject.getTracks().forEach(track => track.stop());\n        }\n      };\n    }\n  }, [isTutorialStarted]); // Only run this effect when the tutorial starts\n\n  // const processFrame = async () => {\n  //   if (!isTutorialStarted || completed || isAudioPlaying) return; // Stop processing if tutorial hasn't started, is completed, or audio is playing\n\n  //   const canvas = canvasRef.current;\n  //   const context = canvas.getContext('2d');\n\n  //   // Ensure video is ready and draw the video feed onto the canvas\n  //   const video = videoRef.current;\n  //   if (video.readyState === video.HAVE_ENOUGH_DATA) {\n  //     context.drawImage(video, 0, 0, canvas.width, canvas.height); // Draw live feed\n\n  //     // Send frame to backend for ArUco detection\n  //     canvas.toBlob(async (blob) => {\n  //       const formData = new FormData();\n  //       formData.append('image', blob, 'frame.jpg');\n  //       try {\n  //         const response = await axios.post('http://localhost:5000/detect', formData, { responseType: 'json' });\n  //         // console.log(\"Response from backend:\", response.data);  // Log response\n\n  //         const { detected, augmented_image, ids, currentStep } = response.data; // Destructure response\n\n  //         if (ids) {\n  //           handleMarkerDetection(ids, currentStep);\n  //         }\n\n  //         // Clear the canvas before drawing the new image\n  //         context.clearRect(0, 0, canvas.width, canvas.height);\n\n  //         // Display processed frame (augmented) coming from backend\n  //         const img = new Image();\n  //         img.src = `data:image/jpeg;base64,${augmented_image}`;\n  //         img.onload = () => {\n  //           context.drawImage(img, 0, 0, canvas.width, canvas.height);\n  //         };\n  //       } catch (err) {\n  //         console.error(\"Error processing frame:\", err);\n  //       }\n  //     }, 'image/jpeg');\n  //   }\n  // };\n\n  const processFrame = async () => {\n    if (!isTutorialStarted || completed || isAudioPlaying) return;\n  \n    const canvas = canvasRef.current;\n    const context = canvas.getContext('2d');\n  \n    // Create an offscreen canvas for double buffering\n    const offscreenCanvas = document.createElement('canvas');\n    const offscreenContext = offscreenCanvas.getContext('2d');\n    offscreenCanvas.width = canvas.width;\n    offscreenCanvas.height = canvas.height;\n  \n    // Ensure the video is ready and draw the video feed onto the offscreen canvas\n    const video = videoRef.current;\n    if (video.readyState === video.HAVE_ENOUGH_DATA) {\n      offscreenContext.drawImage(video, 0, 0, offscreenCanvas.width, offscreenCanvas.height);\n  \n      // Send frame to backend for ArUco detection\n      offscreenCanvas.toBlob(async (blob) => {\n        const formData = new FormData();\n        formData.append('image', blob, 'frame.jpg');\n        try {\n          const response = await axios.post('http://localhost:5000/detect', formData, { responseType: 'json' });\n          const { detected, augmented_image, ids, currentStep, roll } = response.data;\n  \n          if (ids) {\n            handleMarkerDetection(ids, roll);\n          }\n  \n          // Load the augmented image (processed frame from backend)\n          const img = new Image();\n          img.src = `data:image/jpeg;base64,${augmented_image}`;\n          img.onload = () => {\n            // Draw the augmented image on the offscreen canvas\n            offscreenContext.drawImage(img, 0, 0, offscreenCanvas.width, offscreenCanvas.height);\n  \n            // Now copy the entire offscreen canvas to the visible canvas in one step\n            context.clearRect(0, 0, canvas.width, canvas.height); // Clear the main canvas\n            context.drawImage(offscreenCanvas, 0, 0, canvas.width, canvas.height);\n          };\n        } catch (err) {\n          console.error(\"Error processing frame:\", err);\n        }\n      }, 'image/jpeg');\n    }\n  };\n\n\n  const handleMarkerDetection = (ids, roll) => {\n    if (completed) return;\n    // Stop if completed\n\n    const now = new Date().getTime();\n\n    // For step 5, ensure both IDs 1 and 3 are present\n    if (currentStep === 5 && ids.includes(1) && ids.includes(3)) {\n      const roll1 = roll[1];\n      const roll3 = roll[3];\n      if (roll3 > 3 && roll1 < 10){\n        console.log('Step 5: Detected both Marker 1 and Marker 3');\n        setCurrentStep(currentStep + 1);\n        playNextAudio();\n        return;\n      }\n    }\n\n    if (currentStep === 6 && ids.includes(0) && ids.includes(1)) {\n      const roll0 = roll[0];\n      const roll1 = roll[1];\n      if (roll0 < 3 && roll1 < 3){\n        console.log('Step 6: Detected both Marker 0 and Marker 1');\n        setCurrentStep(currentStep + 1);\n        playNextAudio();\n        return;\n      }\n    }\n\n    // // Step 7: Detect marker ID=1 with alternating y-axis conditions\n    // if (currentStep === 7 && ids.includes(1) && !ids.includes(0)) {\n    //   const roll1 = roll[1];\n    //   let bool1= false\n    //   let bool2= false\n    //   if (roll1 > 3) {\n    //     bool1 = true\n    //   }\n    //   else if (roll1 < 3) {\n    //     bool2 = true\n    //   }\n    //   if (bool1 && bool2) {\n    //     console.log('Step 7: Marker 1 detected, alternating y-axis required');\n    //     // Assume the backend sends this information via the currentStepFromBackend\n    //     setCurrentStep(currentStep + 1);\n    //     playNextAudio();\n    //     return;\n    //   }\n\n    // }\n\n    // Ensure these are defined outside the function to persist between calls\n    let previousConditionWasPositive = null; // null initially, tracks the last condition (positive/negative)\n    let alternationCounter = 0; // Tracks number of alternations\n\n    function detectMarkerAndAlternate() {\n      if (currentStep === 7 && ids.includes(1) && !ids.includes(0)) {\n        const roll1 = roll[1]; // Assume roll1 is the value we're checking for alternation\n        let conditionMet = false;\n\n        console.log(`Roll1 value: ${roll1}, Previous condition: ${previousConditionWasPositive}, Alternation Counter: ${alternationCounter}`);\n\n        // If roll1 is positive and the last condition was negative (or null for the first positive check)\n        if (roll1 > 0 && (previousConditionWasPositive === false || previousConditionWasPositive === null)) {\n          previousConditionWasPositive = true; // Update to positive\n          conditionMet = true;\n          console.log(\"Roll1 is positive and previous was negative or null\");\n        }\n        // If roll1 is negative and the last condition was positive\n        else if (roll1 < 0 && previousConditionWasPositive === true) {\n          previousConditionWasPositive = false; // Update to negative\n          conditionMet = true;\n          console.log(\"Roll1 is negative and previous was positive\");\n        }\n\n        // Only increment the counter if an alternation occurred\n        if (conditionMet) {\n          alternationCounter++;\n          console.log(`Alternation detected, Counter: ${alternationCounter}`);\n\n          // Check if we've completed two full alternations (positive → negative → positive)\n          if (alternationCounter >= 2) {\n            console.log('Step 7: Two alternations completed, proceeding to the next step.');\n            setCurrentStep(currentStep + 1);\n            playNextAudio();\n\n            // Reset variables after completion\n            alternationCounter = 0;\n            previousConditionWasPositive = null;\n            return;\n          } else {\n            console.log(`Step 7: Alternation ${alternationCounter} completed, waiting for more alternations.`);\n          }\n        }\n      }\n    }\n\n\n\n\n\n    // Step 8: Detect marker ID=1 with alternating y-axis conditions\n    if (currentStep === 8 && ids.includes(1) && ids.includes(2)) {\n      const roll1 = roll[1];\n      const roll2 = roll[2];\n      if (roll1 < 3 && roll2 > 3) {\n        console.log('Step 8: Detected both Marker 1 and Marker 2');\n        // Assume the backend sends this information via the currentStepFromBackend\n        setCurrentStep(currentStep + 1);\n        playNextAudio();\n        return;\n      }\n    }\n\n    // Step 9: Detect marker ID=1 and marker ID=3\n    if (currentStep === 9 && ids.includes(1) && ids.includes(3)) {\n      const roll1 = roll[1];\n      const roll3 = roll[3];\n      if (roll1 > 3 && roll3 < 3) {\n        console.log('Step 9: Detected both Marker 1 and Marker 3');\n        // Assume the backend sends this information via the currentStepFromBackend\n        setCurrentStep(currentStep + 1);\n        playNextAudio();\n        return;\n      }\n\n    }\n\n    // Step 10: Detect marker ID=1 and marker ID=4\n    if (currentStep === 10 && ids.includes(1) && ids.includes(4)) {\n      const roll1 = roll[1];\n      const roll4 = roll[4];\n      if (roll1 < 3 && roll4 > 3) {\n        console.log('Step 10: Detected both Marker 1 and Marker 4');\n        // Assume the backend sends this information via the currentStepFromBackend\n        setCurrentStep(currentStep + 1);\n        playNextAudio();\n        return;\n      }\n    }\n\n    const expectedMarkerId = currentStep; // Expect the next marker ID\n\n    if (ids.includes(expectedMarkerId)) {\n      console.log(`Step ${expectedMarkerId} verified with marker ID: ${expectedMarkerId}`);\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n    }\n  };\n\n  const playNextAudio = () => {\n    if (currentStep + 2 >= audioRefs.current.length) return; // Prevent out-of-bounds\n\n    const currentAudio = audioRefs.current[currentStep + 2];\n\n    setIsAudioPlaying(true); // Set audio playing to true\n    currentAudio.play().catch(err => console.error(\"Audio play error:\", err));\n\n    currentAudio.onended = () => {\n      setIsAudioPlaying(false); // Set audio playing to false after it finishes\n\n      // Check if this is the last instructional step\n      if (currentStep === audioRefs.current.length - 2) {\n        setCompleted(true);\n        audioRefs.current[audioRefs.current.length - 1].play().catch(err => console.error(\"Audio play error:\", err)); // Play completion audio\n      }\n    };\n  };\n\n  // Trigger the frame processing when the tutorial starts\n  useEffect(() => {\n    if (isTutorialStarted) {\n      const interval = setInterval(processFrame, 1000 / 10); // 10 FPS\n      return () => clearInterval(interval);\n    }\n  }, [isTutorialStarted, currentStep, isAudioPlaying]); // Added isAudioPlaying to the dependency array\n\n  const startTutorial = () => {\n    setIsTutorialStarted(true);\n    audioRefs.current[0].play().catch(err => console.error(\"Audio play error:\", err));\n    audioRefs.current[0].onended = () => {\n      audioRefs.current[1].play().catch(err => console.error(\"Audio play error:\", err));\n    };\n    setCurrentStep(0);\n  };\n\n  return (\n    <div>\n      {!isTutorialStarted && (\n        <button onClick={startTutorial}>Start Tutorial</button>\n      )}\n      {isTutorialStarted && (\n        <div>\n          <video ref={videoRef} style={{ display: 'none' }} />\n          <canvas ref={canvasRef} width=\"640\" height=\"480\" style={{ border: '1px solid black' }} />\n          <p style={{ marginTop: '10px' }}>\n            {stepParagraphs[currentStep - 1] || 'Loading...'}\n          </p>\n          {completed && <p style={{ color: 'blue', marginTop: '10px' }}>Sulfate Ion Test Completed</p>}\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default CameraFeed;\n"],"mappings":";;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAIA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAGA;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAQA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,MAAM,EAAEC,QAAQ,QAAQ,OAAO;AAC1D,OAAOC,KAAK,MAAM,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE1B,MAAMC,UAAU,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACvB,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGP,QAAQ,CAAC,KAAK,CAAC;EAC/C,MAAM,CAACQ,SAAS,EAAEC,YAAY,CAAC,GAAGT,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAACU,WAAW,EAAEC,cAAc,CAAC,GAAGX,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;EACnD,MAAM,CAACY,iBAAiB,EAAEC,oBAAoB,CAAC,GAAGb,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC;EACnE,MAAM,CAACc,cAAc,EAAEC,iBAAiB,CAAC,GAAGf,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC;EAC7D,MAAM,CAACgB,iBAAiB,EAAEC,oBAAoB,CAAC,GAAGjB,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC;EAClE,MAAMkB,QAAQ,GAAGnB,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMoB,SAAS,GAAGpB,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMqB,kBAAkB,GAAGrB,MAAM,CAAC,IAAI,CAAC;EACvC,MAAMsB,gBAAgB,GAAGtB,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC;EACvC,MAAMuB,SAAS,GAAGvB,MAAM,CAAC,CACvB,IAAIwB,KAAK,CAAC,aAAa,CAAC;EAAE;EAC1B,IAAIA,KAAK,CAAC,aAAa,CAAC;EAAE;EAC1B,IAAIA,KAAK,CAAC,aAAa,CAAC;EAAE;EAC1B,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,cAAc,CAAC,EACzB,IAAIA,KAAK,CAAC,cAAc,CAAC,EACzB,IAAIA,KAAK,CAAC,cAAc,CAAC;EACzB;EACA,IAAIA,KAAK,CAAC,cAAc,CAAC,CAAE;EAAA,CAC5B,CAAC;;EAEA;EACA,MAAMC,cAAc,GAAG;IACrB,IAAI,EAAE,6KAA6K;IACnL,CAAC,EAAE,uBAAuB;IAC1B,CAAC,EAAE,uCAAuC;IAC1C,CAAC,EAAE,mCAAmC;IACtC,CAAC,EAAE,mCAAmC;IACtC,CAAC,EAAE,sFAAsF;IACzF,CAAC,EAAE,4CAA4C;IAC/C,CAAC,EAAE,kKAAkK;IACrK,CAAC,EAAE,mSAAmS;IACtS,CAAC,EAAE,iRAAiR;IACpR,CAAC,EAAE,6SAA6S;IAChT,EAAE,EAAE;EACN,CAAC;EAED,MAAMC,sBAAsB,GAAG,IAAI,CAAC,CAAC;;EAEvC;EACA3B,SAAS,CAAC,MAAM;IACd,IAAIc,iBAAiB,EAAE;MACrB,MAAMc,KAAK,GAAGR,QAAQ,CAACS,OAAO;;MAE9B;MACAC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAAEJ,KAAK,EAAE;MAAK,CAAC,CAAC,CACjDK,IAAI,CAAEC,MAAM,IAAK;QAChBN,KAAK,CAACO,SAAS,GAAGD,MAAM;QACxBN,KAAK,CAACQ,gBAAgB,GAAG,MAAM;UAC7BR,KAAK,CAACS,IAAI,CAAC,CAAC;QACd,CAAC;MACH,CAAC,CAAC,CACDC,KAAK,CAACC,GAAG,IAAIC,OAAO,CAACC,KAAK,CAAC,yBAAyB,EAAEF,GAAG,CAAC,CAAC;;MAE9D;MACA,OAAO,MAAM;QACX,IAAIX,KAAK,CAACO,SAAS,EAAE;UACnBP,KAAK,CAACO,SAAS,CAACO,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;QAC5D;MACF,CAAC;IACH;EACF,CAAC,EAAE,CAAC/B,iBAAiB,CAAC,CAAC,CAAC,CAAC;;EAEzB;EACA;;EAEA;EACA;;EAEA;EACA;EACA;EACA;;EAEA;EACA;EACA;EACA;EACA;EACA;EACA;;EAEA;;EAEA;EACA;EACA;;EAEA;EACA;;EAEA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;EAEA,MAAMgC,YAAY,GAAG,MAAAA,CAAA,KAAY;IAC/B,IAAI,CAAChC,iBAAiB,IAAIJ,SAAS,IAAIM,cAAc,EAAE;IAEvD,MAAM+B,MAAM,GAAG1B,SAAS,CAACQ,OAAO;IAChC,MAAMmB,OAAO,GAAGD,MAAM,CAACE,UAAU,CAAC,IAAI,CAAC;;IAEvC;IACA,MAAMC,eAAe,GAAGC,QAAQ,CAACC,aAAa,CAAC,QAAQ,CAAC;IACxD,MAAMC,gBAAgB,GAAGH,eAAe,CAACD,UAAU,CAAC,IAAI,CAAC;IACzDC,eAAe,CAACI,KAAK,GAAGP,MAAM,CAACO,KAAK;IACpCJ,eAAe,CAACK,MAAM,GAAGR,MAAM,CAACQ,MAAM;;IAEtC;IACA,MAAM3B,KAAK,GAAGR,QAAQ,CAACS,OAAO;IAC9B,IAAID,KAAK,CAAC4B,UAAU,KAAK5B,KAAK,CAAC6B,gBAAgB,EAAE;MAC/CJ,gBAAgB,CAACK,SAAS,CAAC9B,KAAK,EAAE,CAAC,EAAE,CAAC,EAAEsB,eAAe,CAACI,KAAK,EAAEJ,eAAe,CAACK,MAAM,CAAC;;MAEtF;MACAL,eAAe,CAACS,MAAM,CAAC,MAAOC,IAAI,IAAK;QACrC,MAAMC,QAAQ,GAAG,IAAIC,QAAQ,CAAC,CAAC;QAC/BD,QAAQ,CAACE,MAAM,CAAC,OAAO,EAAEH,IAAI,EAAE,WAAW,CAAC;QAC3C,IAAI;UACF,MAAMI,QAAQ,GAAG,MAAM7D,KAAK,CAAC8D,IAAI,CAAC,8BAA8B,EAAEJ,QAAQ,EAAE;YAAEK,YAAY,EAAE;UAAO,CAAC,CAAC;UACrG,MAAM;YAAE1D,QAAQ;YAAE2D,eAAe;YAAEC,GAAG;YAAExD,WAAW;YAAEyD;UAAK,CAAC,GAAGL,QAAQ,CAACM,IAAI;UAE3E,IAAIF,GAAG,EAAE;YACPG,qBAAqB,CAACH,GAAG,EAAEC,IAAI,CAAC;UAClC;;UAEA;UACA,MAAMG,GAAG,GAAG,IAAIC,KAAK,CAAC,CAAC;UACvBD,GAAG,CAACE,GAAG,GAAG,0BAA0BP,eAAe,EAAE;UACrDK,GAAG,CAACG,MAAM,GAAG,MAAM;YACjB;YACAtB,gBAAgB,CAACK,SAAS,CAACc,GAAG,EAAE,CAAC,EAAE,CAAC,EAAEtB,eAAe,CAACI,KAAK,EAAEJ,eAAe,CAACK,MAAM,CAAC;;YAEpF;YACAP,OAAO,CAAC4B,SAAS,CAAC,CAAC,EAAE,CAAC,EAAE7B,MAAM,CAACO,KAAK,EAAEP,MAAM,CAACQ,MAAM,CAAC,CAAC,CAAC;YACtDP,OAAO,CAACU,SAAS,CAACR,eAAe,EAAE,CAAC,EAAE,CAAC,EAAEH,MAAM,CAACO,KAAK,EAAEP,MAAM,CAACQ,MAAM,CAAC;UACvE,CAAC;QACH,CAAC,CAAC,OAAOhB,GAAG,EAAE;UACZC,OAAO,CAACC,KAAK,CAAC,yBAAyB,EAAEF,GAAG,CAAC;QAC/C;MACF,CAAC,EAAE,YAAY,CAAC;IAClB;EACF,CAAC;EAGD,MAAMgC,qBAAqB,GAAGA,CAACH,GAAG,EAAEC,IAAI,KAAK;IAC3C,IAAI3D,SAAS,EAAE;IACf;;IAEA,MAAMmE,GAAG,GAAG,IAAIC,IAAI,CAAC,CAAC,CAACC,OAAO,CAAC,CAAC;;IAEhC;IACA,IAAInE,WAAW,KAAK,CAAC,IAAIwD,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,IAAIZ,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,EAAE;MAC3D,MAAMC,KAAK,GAAGZ,IAAI,CAAC,CAAC,CAAC;MACrB,MAAMa,KAAK,GAAGb,IAAI,CAAC,CAAC,CAAC;MACrB,IAAIa,KAAK,GAAG,CAAC,IAAID,KAAK,GAAG,EAAE,EAAC;QAC1BzC,OAAO,CAAC2C,GAAG,CAAC,6CAA6C,CAAC;QAC1DtE,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;QAC/BwE,aAAa,CAAC,CAAC;QACf;MACF;IACF;IAEA,IAAIxE,WAAW,KAAK,CAAC,IAAIwD,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,IAAIZ,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,EAAE;MAC3D,MAAMK,KAAK,GAAGhB,IAAI,CAAC,CAAC,CAAC;MACrB,MAAMY,KAAK,GAAGZ,IAAI,CAAC,CAAC,CAAC;MACrB,IAAIgB,KAAK,GAAG,CAAC,IAAIJ,KAAK,GAAG,CAAC,EAAC;QACzBzC,OAAO,CAAC2C,GAAG,CAAC,6CAA6C,CAAC;QAC1DtE,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;QAC/BwE,aAAa,CAAC,CAAC;QACf;MACF;IACF;;IAEA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;;IAEA;;IAEA;IACA,IAAIE,4BAA4B,GAAG,IAAI,CAAC,CAAC;IACzC,IAAIC,kBAAkB,GAAG,CAAC,CAAC,CAAC;;IAE5B,SAASC,wBAAwBA,CAAA,EAAG;MAClC,IAAI5E,WAAW,KAAK,CAAC,IAAIwD,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,IAAI,CAACZ,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,EAAE;QAC5D,MAAMC,KAAK,GAAGZ,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;QACvB,IAAIoB,YAAY,GAAG,KAAK;QAExBjD,OAAO,CAAC2C,GAAG,CAAC,gBAAgBF,KAAK,yBAAyBK,4BAA4B,0BAA0BC,kBAAkB,EAAE,CAAC;;QAErI;QACA,IAAIN,KAAK,GAAG,CAAC,KAAKK,4BAA4B,KAAK,KAAK,IAAIA,4BAA4B,KAAK,IAAI,CAAC,EAAE;UAClGA,4BAA4B,GAAG,IAAI,CAAC,CAAC;UACrCG,YAAY,GAAG,IAAI;UACnBjD,OAAO,CAAC2C,GAAG,CAAC,qDAAqD,CAAC;QACpE;QACA;QAAA,KACK,IAAIF,KAAK,GAAG,CAAC,IAAIK,4BAA4B,KAAK,IAAI,EAAE;UAC3DA,4BAA4B,GAAG,KAAK,CAAC,CAAC;UACtCG,YAAY,GAAG,IAAI;UACnBjD,OAAO,CAAC2C,GAAG,CAAC,6CAA6C,CAAC;QAC5D;;QAEA;QACA,IAAIM,YAAY,EAAE;UAChBF,kBAAkB,EAAE;UACpB/C,OAAO,CAAC2C,GAAG,CAAC,kCAAkCI,kBAAkB,EAAE,CAAC;;UAEnE;UACA,IAAIA,kBAAkB,IAAI,CAAC,EAAE;YAC3B/C,OAAO,CAAC2C,GAAG,CAAC,kEAAkE,CAAC;YAC/EtE,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;YAC/BwE,aAAa,CAAC,CAAC;;YAEf;YACAG,kBAAkB,GAAG,CAAC;YACtBD,4BAA4B,GAAG,IAAI;YACnC;UACF,CAAC,MAAM;YACL9C,OAAO,CAAC2C,GAAG,CAAC,uBAAuBI,kBAAkB,4CAA4C,CAAC;UACpG;QACF;MACF;IACF;;IAMA;IACA,IAAI3E,WAAW,KAAK,CAAC,IAAIwD,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,IAAIZ,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,EAAE;MAC3D,MAAMC,KAAK,GAAGZ,IAAI,CAAC,CAAC,CAAC;MACrB,MAAMqB,KAAK,GAAGrB,IAAI,CAAC,CAAC,CAAC;MACrB,IAAIY,KAAK,GAAG,CAAC,IAAIS,KAAK,GAAG,CAAC,EAAE;QAC1BlD,OAAO,CAAC2C,GAAG,CAAC,6CAA6C,CAAC;QAC1D;QACAtE,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;QAC/BwE,aAAa,CAAC,CAAC;QACf;MACF;IACF;;IAEA;IACA,IAAIxE,WAAW,KAAK,CAAC,IAAIwD,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,IAAIZ,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,EAAE;MAC3D,MAAMC,KAAK,GAAGZ,IAAI,CAAC,CAAC,CAAC;MACrB,MAAMa,KAAK,GAAGb,IAAI,CAAC,CAAC,CAAC;MACrB,IAAIY,KAAK,GAAG,CAAC,IAAIC,KAAK,GAAG,CAAC,EAAE;QAC1B1C,OAAO,CAAC2C,GAAG,CAAC,6CAA6C,CAAC;QAC1D;QACAtE,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;QAC/BwE,aAAa,CAAC,CAAC;QACf;MACF;IAEF;;IAEA;IACA,IAAIxE,WAAW,KAAK,EAAE,IAAIwD,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,IAAIZ,GAAG,CAACY,QAAQ,CAAC,CAAC,CAAC,EAAE;MAC5D,MAAMC,KAAK,GAAGZ,IAAI,CAAC,CAAC,CAAC;MACrB,MAAMsB,KAAK,GAAGtB,IAAI,CAAC,CAAC,CAAC;MACrB,IAAIY,KAAK,GAAG,CAAC,IAAIU,KAAK,GAAG,CAAC,EAAE;QAC1BnD,OAAO,CAAC2C,GAAG,CAAC,8CAA8C,CAAC;QAC3D;QACAtE,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;QAC/BwE,aAAa,CAAC,CAAC;QACf;MACF;IACF;IAEA,MAAMQ,gBAAgB,GAAGhF,WAAW,CAAC,CAAC;;IAEtC,IAAIwD,GAAG,CAACY,QAAQ,CAACY,gBAAgB,CAAC,EAAE;MAClCpD,OAAO,CAAC2C,GAAG,CAAC,QAAQS,gBAAgB,6BAA6BA,gBAAgB,EAAE,CAAC;MACpF/E,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;MAC/BwE,aAAa,CAAC,CAAC;IACjB;EACF,CAAC;EAED,MAAMA,aAAa,GAAGA,CAAA,KAAM;IAC1B,IAAIxE,WAAW,GAAG,CAAC,IAAIY,SAAS,CAACK,OAAO,CAACgE,MAAM,EAAE,OAAO,CAAC;;IAEzD,MAAMC,YAAY,GAAGtE,SAAS,CAACK,OAAO,CAACjB,WAAW,GAAG,CAAC,CAAC;IAEvDK,iBAAiB,CAAC,IAAI,CAAC,CAAC,CAAC;IACzB6E,YAAY,CAACzD,IAAI,CAAC,CAAC,CAACC,KAAK,CAACC,GAAG,IAAIC,OAAO,CAACC,KAAK,CAAC,mBAAmB,EAAEF,GAAG,CAAC,CAAC;IAEzEuD,YAAY,CAACC,OAAO,GAAG,MAAM;MAC3B9E,iBAAiB,CAAC,KAAK,CAAC,CAAC,CAAC;;MAE1B;MACA,IAAIL,WAAW,KAAKY,SAAS,CAACK,OAAO,CAACgE,MAAM,GAAG,CAAC,EAAE;QAChDlF,YAAY,CAAC,IAAI,CAAC;QAClBa,SAAS,CAACK,OAAO,CAACL,SAAS,CAACK,OAAO,CAACgE,MAAM,GAAG,CAAC,CAAC,CAACxD,IAAI,CAAC,CAAC,CAACC,KAAK,CAACC,GAAG,IAAIC,OAAO,CAACC,KAAK,CAAC,mBAAmB,EAAEF,GAAG,CAAC,CAAC,CAAC,CAAC;MAChH;IACF,CAAC;EACH,CAAC;;EAED;EACAvC,SAAS,CAAC,MAAM;IACd,IAAIc,iBAAiB,EAAE;MACrB,MAAMkF,QAAQ,GAAGC,WAAW,CAACnD,YAAY,EAAE,IAAI,GAAG,EAAE,CAAC,CAAC,CAAC;MACvD,OAAO,MAAMoD,aAAa,CAACF,QAAQ,CAAC;IACtC;EACF,CAAC,EAAE,CAAClF,iBAAiB,EAAEF,WAAW,EAAEI,cAAc,CAAC,CAAC,CAAC,CAAC;;EAEtD,MAAMmF,aAAa,GAAGA,CAAA,KAAM;IAC1BpF,oBAAoB,CAAC,IAAI,CAAC;IAC1BS,SAAS,CAACK,OAAO,CAAC,CAAC,CAAC,CAACQ,IAAI,CAAC,CAAC,CAACC,KAAK,CAACC,GAAG,IAAIC,OAAO,CAACC,KAAK,CAAC,mBAAmB,EAAEF,GAAG,CAAC,CAAC;IACjFf,SAAS,CAACK,OAAO,CAAC,CAAC,CAAC,CAACkE,OAAO,GAAG,MAAM;MACnCvE,SAAS,CAACK,OAAO,CAAC,CAAC,CAAC,CAACQ,IAAI,CAAC,CAAC,CAACC,KAAK,CAACC,GAAG,IAAIC,OAAO,CAACC,KAAK,CAAC,mBAAmB,EAAEF,GAAG,CAAC,CAAC;IACnF,CAAC;IACD1B,cAAc,CAAC,CAAC,CAAC;EACnB,CAAC;EAED,oBACER,OAAA;IAAA+F,QAAA,GACG,CAACtF,iBAAiB,iBACjBT,OAAA;MAAQgG,OAAO,EAAEF,aAAc;MAAAC,QAAA,EAAC;IAAc;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CACvD,EACA3F,iBAAiB,iBAChBT,OAAA;MAAA+F,QAAA,gBACE/F,OAAA;QAAOqG,GAAG,EAAEtF,QAAS;QAACuF,KAAK,EAAE;UAAEC,OAAO,EAAE;QAAO;MAAE;QAAAN,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAE,CAAC,eACpDpG,OAAA;QAAQqG,GAAG,EAAErF,SAAU;QAACiC,KAAK,EAAC,KAAK;QAACC,MAAM,EAAC,KAAK;QAACoD,KAAK,EAAE;UAAEE,MAAM,EAAE;QAAkB;MAAE;QAAAP,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAE,CAAC,eACzFpG,OAAA;QAAGsG,KAAK,EAAE;UAAEG,SAAS,EAAE;QAAO,CAAE;QAAAV,QAAA,EAC7B1E,cAAc,CAACd,WAAW,GAAG,CAAC,CAAC,IAAI;MAAY;QAAA0F,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC/C,CAAC,EACH/F,SAAS,iBAAIL,OAAA;QAAGsG,KAAK,EAAE;UAAEI,KAAK,EAAE,MAAM;UAAED,SAAS,EAAE;QAAO,CAAE;QAAAV,QAAA,EAAC;MAA0B;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACzF,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV,CAAC;AAAClG,EAAA,CAzWID,UAAU;AAAA0G,EAAA,GAAV1G,UAAU;AA2WhB,eAAeA,UAAU;AAAC,IAAA0G,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}