{"ast":null,"code":"var _jsxFileName = \"/home/user/Documents/Aruco_POC/aruco-detector/src/CameraFeed.js\",\n  _s = $RefreshSig$();\n// import React, { useEffect, useRef, useState } from 'react';\n// import axios from 'axios';\n\n// const CameraFeed = () => {\n//   const [detected, setDetected] = useState(false)  \n//   const videoRef = useRef(null);\n//   const canvasRef = useRef(null);\n//   const [processing, setProcessing] = useState(false);\n\n//   useEffect(() => {\n//     const video = videoRef.current;\n\n//     // Request access to the webcam\n//     navigator.mediaDevices.getUserMedia({ video: true })\n//       .then((stream) => {\n//         video.srcObject = stream;\n\n//         // Only call play() when the video is loaded\n//         video.onloadedmetadata = () => {\n//           video.play().catch(error => console.error(\"Error playing video:\", error));\n//         };\n//       })\n//       .catch(err => console.error(\"Error accessing webcam:\", err));\n\n//     return () => {\n//       if (video.srcObject) {\n//         video.srcObject.getTracks().forEach(track => track.stop()); // Stop webcam access when the component unmounts\n//       }\n//     };\n//   }, []);\n\n//   let lastProcessedTime = Date.now();\n\n//   const processFrame = async () => {\n//     const currentTime = Date.now();\n//     const timeDiff = currentTime - lastProcessedTime;\n\n//     // Adjust frame rate by only sending frames every 200ms (5 FPS, adjust as necessary)\n//     if (timeDiff < 200) {\n//       return;\n//     }\n\n//     lastProcessedTime = currentTime;\n\n//     const canvas = canvasRef.current;\n//     const bufferCanvas = document.createElement('canvas');  // Create an off-screen buffer canvas\n//     bufferCanvas.width = canvas.width;\n//     bufferCanvas.height = canvas.height;\n\n//     const context = canvas.getContext('2d');\n//     const bufferContext = bufferCanvas.getContext('2d');  // Context for the off-screen canvas\n\n//     // Draw the current frame from video on buffer canvas\n//     bufferContext.drawImage(videoRef.current, 0, 0, bufferCanvas.width, bufferCanvas.height);\n\n//     // Convert the frame to Blob and send to the backend for processing\n//     bufferCanvas.toBlob(async (blob) => {\n//       const formData = new FormData();\n//       formData.append('image', blob, 'frame.jpg');\n\n//       try {\n//         setProcessing(true);\n//         const response = await axios.post('http://localhost:5000/detect', formData, {\n//           responseType: 'blob'\n//         });\n\n//         // Create an image object from the returned blob\n//         const img = new Image();\n//         img.src = URL.createObjectURL(response.data);\n//         img.onload = () => {\n//           context.clearRect(0, 0, canvas.width, canvas.height);  // Clear the previous frame\n//           context.drawImage(img, 0, 0, canvas.width, canvas.height);  // Draw the augmented frame\n//           setProcessing(false);\n//           setDetected(true)\n//         };\n\n//       } catch (err) {\n//         console.error(\"Error processing frame:\", err);\n//         setProcessing(false);\n//       }\n//     }, 'image/jpeg');\n//   };\n\n//   useEffect(() => {\n//     const interval = setInterval(processFrame, 1000 / 10); // Process 10 frames per second\n//     return () => clearInterval(interval);\n//   }, []);\n\n//   return (\n//     <div>\n//       <video ref={videoRef} style={{ display: 'none' }} />\n//       <canvas ref={canvasRef} width=\"640\" height=\"480\" />\n//       {/* {processing } */}\n//     {/* Display the text \"Chemical pouring\" when marker is detected */}\n//     {detected && <p style={{ color: 'green', marginTop: '10px' }}>Chemical pouring</p>}\n//     </div>\n//   );\n// };\n\n// export default CameraFeed;\n\n// import React, { useEffect, useRef, useState } from 'react';\n// import axios from 'axios';\n\n// const CameraFeed = () => {\n//   const [detected, setDetected] = useState(false);\n//   const videoRef = useRef(null);\n//   const canvasRef = useRef(null);\n//   const [processing, setProcessing] = useState(false);\n\n//   useEffect(() => {\n//     const video = videoRef.current;\n\n//     // Request access to the webcam\n//     navigator.mediaDevices.getUserMedia({ video: true })\n//       .then((stream) => {\n//         video.srcObject = stream;\n\n//         // Only call play() when the video is loaded\n//         video.onloadedmetadata = () => {\n//           video.play().catch(error => console.error(\"Error playing video:\", error));\n//         };\n//       })\n//       .catch(err => console.error(\"Error accessing webcam:\", err));\n\n//     return () => {\n//       if (video.srcObject) {\n//         video.srcObject.getTracks().forEach(track => track.stop()); // Stop webcam access when the component unmounts\n//       }\n//     };\n//   }, []);\n\n//   let lastProcessedTime = Date.now();\n\n//   const processFrame = async () => {\n//     const currentTime = Date.now();\n//     const timeDiff = currentTime - lastProcessedTime;\n\n//     // Adjust frame rate by only sending frames every 200ms (5 FPS, adjust as necessary)\n//     if (timeDiff < 200) {\n//       return;\n//     }\n\n//     lastProcessedTime = currentTime;\n\n//     const canvas = canvasRef.current;\n//     const bufferCanvas = document.createElement('canvas');  // Create an off-screen buffer canvas\n//     bufferCanvas.width = canvas.width;\n//     bufferCanvas.height = canvas.height;\n\n//     const context = canvas.getContext('2d');\n//     const bufferContext = bufferCanvas.getContext('2d');  // Context for the off-screen canvas\n\n//     // Draw the current frame from video on buffer canvas\n//     bufferContext.drawImage(videoRef.current, 0, 0, bufferCanvas.width, bufferCanvas.height);\n\n//     // Convert the frame to Blob and send to the backend for processing\n//     bufferCanvas.toBlob(async (blob) => {\n//       const formData = new FormData();\n//       formData.append('image', blob, 'frame.jpg');\n\n//       try {\n//         setProcessing(true);\n//         const response = await axios.post('http://localhost:5000/detect', formData, {\n//           responseType: 'json'\n//         });\n\n//         // Handle the response\n//         const { detected, augmented_image } = response.data;\n\n//         // Create an image object from the base64 encoded image\n//         const img = new Image();\n//         img.src = `data:image/jpeg;base64,${augmented_image}`;\n//         img.onload = () => {\n//           const canvasContext = canvas.getContext('2d');\n//           canvasContext.drawImage(img, 0, 0, canvas.width, canvas.height);  // Draw the augmented frame\n//           setProcessing(false);\n//           setDetected(detected);  // Set detected based on the backend response\n//         };\n\n//       } catch (err) {\n//         console.error(\"Error processing frame:\", err);\n//         setProcessing(false);\n//         setDetected(false);  // Ensure detection state is false if an error occurs\n//       }\n//     }, 'image/jpeg');\n//   };\n\n//   useEffect(() => {\n//     const interval = setInterval(processFrame, 1000 / 10); // Process 10 frames per second\n//     return () => clearInterval(interval);\n//   }, []);\n\n//   return (\n//     <div>\n//       <video ref={videoRef} style={{ display: 'none' }} />\n//       <canvas ref={canvasRef} width=\"640\" height=\"480\" />\n//       {/* Display the text \"Chemical pouring\" only when marker is detected */}\n//       {detected && <p style={{ color: 'green', marginTop: '10px' }}>Chemical pouring</p>}\n//     </div>\n//   );\n// };\n\n// export default CameraFeed;\n\nimport React, { useEffect, useRef, useState } from 'react';\nimport axios from 'axios';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst CameraFeed = () => {\n  _s();\n  const [detected, setDetected] = useState(false);\n  const [completed, setCompleted] = useState(false); // Track task completion\n  const [isAudioPlaying, setIsAudioPlaying] = useState(false); // Track if audio is playing\n  const [userInteracted, setUserInteracted] = useState(false); // Track user interaction\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  const audioRef = useRef(new Audio('aruco-detector/src/distilled_water.mp3')); // Load the audio file\n\n  useEffect(() => {\n    const video = videoRef.current;\n\n    // Request access to the webcam\n    navigator.mediaDevices.getUserMedia({\n      video: true\n    }).then(stream => {\n      video.srcObject = stream;\n\n      // Only call play() when the video is loaded\n      video.onloadedmetadata = () => {\n        video.play().catch(error => console.error(\"Error playing video:\", error));\n      };\n    }).catch(err => console.error(\"Error accessing webcam:\", err));\n    return () => {\n      if (video.srcObject) {\n        video.srcObject.getTracks().forEach(track => track.stop()); // Stop webcam access when component unmounts\n      }\n    };\n  }, []);\n  const startDetection = () => {\n    setUserInteracted(true); // Mark that the user has interacted\n\n    // Play audio when the button is clicked\n    audioRef.current.play();\n    setIsAudioPlaying(true);\n    audioRef.current.onended = () => {\n      setIsAudioPlaying(false); // Set to false once the audio finishes\n    };\n  };\n  let lastProcessedTime = Date.now();\n  const processFrame = async () => {\n    const currentTime = Date.now();\n    const timeDiff = currentTime - lastProcessedTime;\n\n    // Adjust frame rate by only sending frames every 200ms (5 FPS)\n    if (timeDiff < 200 || isAudioPlaying || completed || !userInteracted) {\n      return; // Only process frames if audio has finished, task is not completed, and user has interacted\n    }\n    lastProcessedTime = currentTime;\n    const canvas = canvasRef.current;\n    const bufferCanvas = document.createElement('canvas'); // Off-screen buffer canvas\n    bufferCanvas.width = canvas.width;\n    bufferCanvas.height = canvas.height;\n    const bufferContext = bufferCanvas.getContext('2d'); // Off-screen canvas context\n\n    // Draw the current frame from video on buffer canvas\n    bufferContext.drawImage(videoRef.current, 0, 0, bufferCanvas.width, bufferCanvas.height);\n\n    // Convert the frame to Blob and send to the backend for processing\n    bufferCanvas.toBlob(async blob => {\n      const formData = new FormData();\n      formData.append('image', blob, 'frame.jpg');\n      try {\n        const response = await axios.post('http://localhost:5000/detect', formData, {\n          responseType: 'json'\n        });\n\n        // Handle the response\n        const {\n          detected,\n          augmented_image\n        } = response.data;\n\n        // Create an image object from the base64 encoded image\n        const img = new Image();\n        img.src = `data:image/jpeg;base64,${augmented_image}`;\n        img.onload = () => {\n          const canvasContext = canvas.getContext('2d');\n          canvasContext.drawImage(img, 0, 0, canvas.width, canvas.height); // Draw the augmented frame\n          setDetected(detected); // Set detected state based on the backend response\n\n          // Mark as completed if the ArUco marker is detected\n          if (detected) {\n            setCompleted(true);\n          }\n        };\n      } catch (err) {\n        console.error(\"Error processing frame:\", err);\n        setDetected(false); // Ensure detection state is false if an error occurs\n      }\n    }, 'image/jpeg');\n  };\n  useEffect(() => {\n    const interval = setInterval(processFrame, 1000 / 10); // Process 10 frames per second\n    return () => clearInterval(interval);\n  }, [isAudioPlaying, completed, userInteracted]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [!userInteracted && /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: startDetection,\n      style: {\n        marginBottom: '10px'\n      },\n      children: \"Start Detection\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 327,\n      columnNumber: 9\n    }, this), /*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      style: {\n        display: 'none'\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 332,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      width: \"640\",\n      height: \"480\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 333,\n      columnNumber: 7\n    }, this), detected && /*#__PURE__*/_jsxDEV(\"p\", {\n      style: {\n        color: 'green',\n        marginTop: '10px'\n      },\n      children: \"Chemical pouring\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 335,\n      columnNumber: 20\n    }, this), completed && /*#__PURE__*/_jsxDEV(\"p\", {\n      style: {\n        color: 'blue',\n        marginTop: '10px'\n      },\n      children: \"Completed\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 338,\n      columnNumber: 21\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 324,\n    columnNumber: 5\n  }, this);\n};\n_s(CameraFeed, \"DszXA4RS5WjyWBQlKQt3/z1yYYM=\");\n_c = CameraFeed;\nexport default CameraFeed;\nvar _c;\n$RefreshReg$(_c, \"CameraFeed\");","map":{"version":3,"names":["React","useEffect","useRef","useState","axios","jsxDEV","_jsxDEV","CameraFeed","_s","detected","setDetected","completed","setCompleted","isAudioPlaying","setIsAudioPlaying","userInteracted","setUserInteracted","videoRef","canvasRef","audioRef","Audio","video","current","navigator","mediaDevices","getUserMedia","then","stream","srcObject","onloadedmetadata","play","catch","error","console","err","getTracks","forEach","track","stop","startDetection","onended","lastProcessedTime","Date","now","processFrame","currentTime","timeDiff","canvas","bufferCanvas","document","createElement","width","height","bufferContext","getContext","drawImage","toBlob","blob","formData","FormData","append","response","post","responseType","augmented_image","data","img","Image","src","onload","canvasContext","interval","setInterval","clearInterval","children","onClick","style","marginBottom","fileName","_jsxFileName","lineNumber","columnNumber","ref","display","color","marginTop","_c","$RefreshReg$"],"sources":["/home/user/Documents/Aruco_POC/aruco-detector/src/CameraFeed.js"],"sourcesContent":["// import React, { useEffect, useRef, useState } from 'react';\n// import axios from 'axios';\n\n// const CameraFeed = () => {\n//   const [detected, setDetected] = useState(false)  \n//   const videoRef = useRef(null);\n//   const canvasRef = useRef(null);\n//   const [processing, setProcessing] = useState(false);\n  \n//   useEffect(() => {\n//     const video = videoRef.current;\n  \n//     // Request access to the webcam\n//     navigator.mediaDevices.getUserMedia({ video: true })\n//       .then((stream) => {\n//         video.srcObject = stream;\n  \n//         // Only call play() when the video is loaded\n//         video.onloadedmetadata = () => {\n//           video.play().catch(error => console.error(\"Error playing video:\", error));\n//         };\n//       })\n//       .catch(err => console.error(\"Error accessing webcam:\", err));\n  \n//     return () => {\n//       if (video.srcObject) {\n//         video.srcObject.getTracks().forEach(track => track.stop()); // Stop webcam access when the component unmounts\n//       }\n//     };\n//   }, []);\n\n\n//   let lastProcessedTime = Date.now();\n\n//   const processFrame = async () => {\n//     const currentTime = Date.now();\n//     const timeDiff = currentTime - lastProcessedTime;\n  \n//     // Adjust frame rate by only sending frames every 200ms (5 FPS, adjust as necessary)\n//     if (timeDiff < 200) {\n//       return;\n//     }\n  \n//     lastProcessedTime = currentTime;\n  \n//     const canvas = canvasRef.current;\n//     const bufferCanvas = document.createElement('canvas');  // Create an off-screen buffer canvas\n//     bufferCanvas.width = canvas.width;\n//     bufferCanvas.height = canvas.height;\n  \n//     const context = canvas.getContext('2d');\n//     const bufferContext = bufferCanvas.getContext('2d');  // Context for the off-screen canvas\n    \n//     // Draw the current frame from video on buffer canvas\n//     bufferContext.drawImage(videoRef.current, 0, 0, bufferCanvas.width, bufferCanvas.height);\n    \n//     // Convert the frame to Blob and send to the backend for processing\n//     bufferCanvas.toBlob(async (blob) => {\n//       const formData = new FormData();\n//       formData.append('image', blob, 'frame.jpg');\n  \n//       try {\n//         setProcessing(true);\n//         const response = await axios.post('http://localhost:5000/detect', formData, {\n//           responseType: 'blob'\n//         });\n        \n//         // Create an image object from the returned blob\n//         const img = new Image();\n//         img.src = URL.createObjectURL(response.data);\n//         img.onload = () => {\n//           context.clearRect(0, 0, canvas.width, canvas.height);  // Clear the previous frame\n//           context.drawImage(img, 0, 0, canvas.width, canvas.height);  // Draw the augmented frame\n//           setProcessing(false);\n//           setDetected(true)\n//         };\n        \n//       } catch (err) {\n//         console.error(\"Error processing frame:\", err);\n//         setProcessing(false);\n//       }\n//     }, 'image/jpeg');\n//   };\n  \n  \n\n//   useEffect(() => {\n//     const interval = setInterval(processFrame, 1000 / 10); // Process 10 frames per second\n//     return () => clearInterval(interval);\n//   }, []);\n\n//   return (\n//     <div>\n//       <video ref={videoRef} style={{ display: 'none' }} />\n//       <canvas ref={canvasRef} width=\"640\" height=\"480\" />\n//       {/* {processing } */}\n//     {/* Display the text \"Chemical pouring\" when marker is detected */}\n//     {detected && <p style={{ color: 'green', marginTop: '10px' }}>Chemical pouring</p>}\n//     </div>\n//   );\n// };\n\n// export default CameraFeed;\n\n\n\n// import React, { useEffect, useRef, useState } from 'react';\n// import axios from 'axios';\n\n// const CameraFeed = () => {\n//   const [detected, setDetected] = useState(false);\n//   const videoRef = useRef(null);\n//   const canvasRef = useRef(null);\n//   const [processing, setProcessing] = useState(false);\n\n//   useEffect(() => {\n//     const video = videoRef.current;\n\n//     // Request access to the webcam\n//     navigator.mediaDevices.getUserMedia({ video: true })\n//       .then((stream) => {\n//         video.srcObject = stream;\n\n//         // Only call play() when the video is loaded\n//         video.onloadedmetadata = () => {\n//           video.play().catch(error => console.error(\"Error playing video:\", error));\n//         };\n//       })\n//       .catch(err => console.error(\"Error accessing webcam:\", err));\n\n//     return () => {\n//       if (video.srcObject) {\n//         video.srcObject.getTracks().forEach(track => track.stop()); // Stop webcam access when the component unmounts\n//       }\n//     };\n//   }, []);\n\n//   let lastProcessedTime = Date.now();\n\n//   const processFrame = async () => {\n//     const currentTime = Date.now();\n//     const timeDiff = currentTime - lastProcessedTime;\n\n//     // Adjust frame rate by only sending frames every 200ms (5 FPS, adjust as necessary)\n//     if (timeDiff < 200) {\n//       return;\n//     }\n\n//     lastProcessedTime = currentTime;\n\n//     const canvas = canvasRef.current;\n//     const bufferCanvas = document.createElement('canvas');  // Create an off-screen buffer canvas\n//     bufferCanvas.width = canvas.width;\n//     bufferCanvas.height = canvas.height;\n\n//     const context = canvas.getContext('2d');\n//     const bufferContext = bufferCanvas.getContext('2d');  // Context for the off-screen canvas\n\n//     // Draw the current frame from video on buffer canvas\n//     bufferContext.drawImage(videoRef.current, 0, 0, bufferCanvas.width, bufferCanvas.height);\n\n//     // Convert the frame to Blob and send to the backend for processing\n//     bufferCanvas.toBlob(async (blob) => {\n//       const formData = new FormData();\n//       formData.append('image', blob, 'frame.jpg');\n\n//       try {\n//         setProcessing(true);\n//         const response = await axios.post('http://localhost:5000/detect', formData, {\n//           responseType: 'json'\n//         });\n\n//         // Handle the response\n//         const { detected, augmented_image } = response.data;\n\n//         // Create an image object from the base64 encoded image\n//         const img = new Image();\n//         img.src = `data:image/jpeg;base64,${augmented_image}`;\n//         img.onload = () => {\n//           const canvasContext = canvas.getContext('2d');\n//           canvasContext.drawImage(img, 0, 0, canvas.width, canvas.height);  // Draw the augmented frame\n//           setProcessing(false);\n//           setDetected(detected);  // Set detected based on the backend response\n//         };\n\n//       } catch (err) {\n//         console.error(\"Error processing frame:\", err);\n//         setProcessing(false);\n//         setDetected(false);  // Ensure detection state is false if an error occurs\n//       }\n//     }, 'image/jpeg');\n//   };\n\n//   useEffect(() => {\n//     const interval = setInterval(processFrame, 1000 / 10); // Process 10 frames per second\n//     return () => clearInterval(interval);\n//   }, []);\n\n//   return (\n//     <div>\n//       <video ref={videoRef} style={{ display: 'none' }} />\n//       <canvas ref={canvasRef} width=\"640\" height=\"480\" />\n//       {/* Display the text \"Chemical pouring\" only when marker is detected */}\n//       {detected && <p style={{ color: 'green', marginTop: '10px' }}>Chemical pouring</p>}\n//     </div>\n//   );\n// };\n\n// export default CameraFeed;\n\n\n\n\n\nimport React, { useEffect, useRef, useState } from 'react';\nimport axios from 'axios';\n\nconst CameraFeed = () => {\n  const [detected, setDetected] = useState(false);\n  const [completed, setCompleted] = useState(false);  // Track task completion\n  const [isAudioPlaying, setIsAudioPlaying] = useState(false);  // Track if audio is playing\n  const [userInteracted, setUserInteracted] = useState(false);  // Track user interaction\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  const audioRef = useRef(new Audio('aruco-detector/src/distilled_water.mp3'));  // Load the audio file\n\n  useEffect(() => {\n    const video = videoRef.current;\n\n    // Request access to the webcam\n    navigator.mediaDevices.getUserMedia({ video: true })\n      .then((stream) => {\n        video.srcObject = stream;\n\n        // Only call play() when the video is loaded\n        video.onloadedmetadata = () => {\n          video.play().catch(error => console.error(\"Error playing video:\", error));\n        };\n      })\n      .catch(err => console.error(\"Error accessing webcam:\", err));\n\n    return () => {\n      if (video.srcObject) {\n        video.srcObject.getTracks().forEach(track => track.stop());  // Stop webcam access when component unmounts\n      }\n    };\n  }, []);\n\n  const startDetection = () => {\n    setUserInteracted(true);  // Mark that the user has interacted\n\n    // Play audio when the button is clicked\n    audioRef.current.play();\n    setIsAudioPlaying(true);\n\n    audioRef.current.onended = () => {\n      setIsAudioPlaying(false);  // Set to false once the audio finishes\n    };\n  };\n\n  let lastProcessedTime = Date.now();\n\n  const processFrame = async () => {\n    const currentTime = Date.now();\n    const timeDiff = currentTime - lastProcessedTime;\n\n    // Adjust frame rate by only sending frames every 200ms (5 FPS)\n    if (timeDiff < 200 || isAudioPlaying || completed || !userInteracted) {\n      return;  // Only process frames if audio has finished, task is not completed, and user has interacted\n    }\n\n    lastProcessedTime = currentTime;\n\n    const canvas = canvasRef.current;\n    const bufferCanvas = document.createElement('canvas');  // Off-screen buffer canvas\n    bufferCanvas.width = canvas.width;\n    bufferCanvas.height = canvas.height;\n\n    const bufferContext = bufferCanvas.getContext('2d');  // Off-screen canvas context\n\n    // Draw the current frame from video on buffer canvas\n    bufferContext.drawImage(videoRef.current, 0, 0, bufferCanvas.width, bufferCanvas.height);\n\n    // Convert the frame to Blob and send to the backend for processing\n    bufferCanvas.toBlob(async (blob) => {\n      const formData = new FormData();\n      formData.append('image', blob, 'frame.jpg');\n\n      try {\n        const response = await axios.post('http://localhost:5000/detect', formData, {\n          responseType: 'json'\n        });\n\n        // Handle the response\n        const { detected, augmented_image } = response.data;\n\n        // Create an image object from the base64 encoded image\n        const img = new Image();\n        img.src = `data:image/jpeg;base64,${augmented_image}`;\n        img.onload = () => {\n          const canvasContext = canvas.getContext('2d');\n          canvasContext.drawImage(img, 0, 0, canvas.width, canvas.height);  // Draw the augmented frame\n          setDetected(detected);  // Set detected state based on the backend response\n\n          // Mark as completed if the ArUco marker is detected\n          if (detected) {\n            setCompleted(true);\n          }\n        };\n\n      } catch (err) {\n        console.error(\"Error processing frame:\", err);\n        setDetected(false);  // Ensure detection state is false if an error occurs\n      }\n    }, 'image/jpeg');\n  };\n\n  useEffect(() => {\n    const interval = setInterval(processFrame, 1000 / 10);  // Process 10 frames per second\n    return () => clearInterval(interval);\n  }, [isAudioPlaying, completed, userInteracted]);\n\n  return (\n    <div>\n      {/* Button to start detection (user interaction required for audio playback) */}\n      {!userInteracted && (\n        <button onClick={startDetection} style={{ marginBottom: '10px' }}>\n          Start Detection\n        </button>\n      )}\n\n      <video ref={videoRef} style={{ display: 'none' }} />\n      <canvas ref={canvasRef} width=\"640\" height=\"480\" />\n      {/* Display the text \"Chemical pouring\" only when the marker is detected */}\n      {detected && <p style={{ color: 'green', marginTop: '10px' }}>Chemical pouring</p>}\n\n      {/* Display \"Completed\" below the canvas once the task is done */}\n      {completed && <p style={{ color: 'blue', marginTop: '10px' }}>Completed</p>}\n    </div>\n  );\n};\n\nexport default CameraFeed;\n"],"mappings":";;AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAIA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAIA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAMA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,MAAM,EAAEC,QAAQ,QAAQ,OAAO;AAC1D,OAAOC,KAAK,MAAM,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE1B,MAAMC,UAAU,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACvB,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGP,QAAQ,CAAC,KAAK,CAAC;EAC/C,MAAM,CAACQ,SAAS,EAAEC,YAAY,CAAC,GAAGT,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAE;EACpD,MAAM,CAACU,cAAc,EAAEC,iBAAiB,CAAC,GAAGX,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAE;EAC9D,MAAM,CAACY,cAAc,EAAEC,iBAAiB,CAAC,GAAGb,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAE;EAC9D,MAAMc,QAAQ,GAAGf,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMgB,SAAS,GAAGhB,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMiB,QAAQ,GAAGjB,MAAM,CAAC,IAAIkB,KAAK,CAAC,wCAAwC,CAAC,CAAC,CAAC,CAAE;;EAE/EnB,SAAS,CAAC,MAAM;IACd,MAAMoB,KAAK,GAAGJ,QAAQ,CAACK,OAAO;;IAE9B;IACAC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;MAAEJ,KAAK,EAAE;IAAK,CAAC,CAAC,CACjDK,IAAI,CAAEC,MAAM,IAAK;MAChBN,KAAK,CAACO,SAAS,GAAGD,MAAM;;MAExB;MACAN,KAAK,CAACQ,gBAAgB,GAAG,MAAM;QAC7BR,KAAK,CAACS,IAAI,CAAC,CAAC,CAACC,KAAK,CAACC,KAAK,IAAIC,OAAO,CAACD,KAAK,CAAC,sBAAsB,EAAEA,KAAK,CAAC,CAAC;MAC3E,CAAC;IACH,CAAC,CAAC,CACDD,KAAK,CAACG,GAAG,IAAID,OAAO,CAACD,KAAK,CAAC,yBAAyB,EAAEE,GAAG,CAAC,CAAC;IAE9D,OAAO,MAAM;MACX,IAAIb,KAAK,CAACO,SAAS,EAAE;QACnBP,KAAK,CAACO,SAAS,CAACO,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAE;MAC/D;IACF,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMC,cAAc,GAAGA,CAAA,KAAM;IAC3BvB,iBAAiB,CAAC,IAAI,CAAC,CAAC,CAAE;;IAE1B;IACAG,QAAQ,CAACG,OAAO,CAACQ,IAAI,CAAC,CAAC;IACvBhB,iBAAiB,CAAC,IAAI,CAAC;IAEvBK,QAAQ,CAACG,OAAO,CAACkB,OAAO,GAAG,MAAM;MAC/B1B,iBAAiB,CAAC,KAAK,CAAC,CAAC,CAAE;IAC7B,CAAC;EACH,CAAC;EAED,IAAI2B,iBAAiB,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;EAElC,MAAMC,YAAY,GAAG,MAAAA,CAAA,KAAY;IAC/B,MAAMC,WAAW,GAAGH,IAAI,CAACC,GAAG,CAAC,CAAC;IAC9B,MAAMG,QAAQ,GAAGD,WAAW,GAAGJ,iBAAiB;;IAEhD;IACA,IAAIK,QAAQ,GAAG,GAAG,IAAIjC,cAAc,IAAIF,SAAS,IAAI,CAACI,cAAc,EAAE;MACpE,OAAO,CAAE;IACX;IAEA0B,iBAAiB,GAAGI,WAAW;IAE/B,MAAME,MAAM,GAAG7B,SAAS,CAACI,OAAO;IAChC,MAAM0B,YAAY,GAAGC,QAAQ,CAACC,aAAa,CAAC,QAAQ,CAAC,CAAC,CAAE;IACxDF,YAAY,CAACG,KAAK,GAAGJ,MAAM,CAACI,KAAK;IACjCH,YAAY,CAACI,MAAM,GAAGL,MAAM,CAACK,MAAM;IAEnC,MAAMC,aAAa,GAAGL,YAAY,CAACM,UAAU,CAAC,IAAI,CAAC,CAAC,CAAE;;IAEtD;IACAD,aAAa,CAACE,SAAS,CAACtC,QAAQ,CAACK,OAAO,EAAE,CAAC,EAAE,CAAC,EAAE0B,YAAY,CAACG,KAAK,EAAEH,YAAY,CAACI,MAAM,CAAC;;IAExF;IACAJ,YAAY,CAACQ,MAAM,CAAC,MAAOC,IAAI,IAAK;MAClC,MAAMC,QAAQ,GAAG,IAAIC,QAAQ,CAAC,CAAC;MAC/BD,QAAQ,CAACE,MAAM,CAAC,OAAO,EAAEH,IAAI,EAAE,WAAW,CAAC;MAE3C,IAAI;QACF,MAAMI,QAAQ,GAAG,MAAMzD,KAAK,CAAC0D,IAAI,CAAC,8BAA8B,EAAEJ,QAAQ,EAAE;UAC1EK,YAAY,EAAE;QAChB,CAAC,CAAC;;QAEF;QACA,MAAM;UAAEtD,QAAQ;UAAEuD;QAAgB,CAAC,GAAGH,QAAQ,CAACI,IAAI;;QAEnD;QACA,MAAMC,GAAG,GAAG,IAAIC,KAAK,CAAC,CAAC;QACvBD,GAAG,CAACE,GAAG,GAAG,0BAA0BJ,eAAe,EAAE;QACrDE,GAAG,CAACG,MAAM,GAAG,MAAM;UACjB,MAAMC,aAAa,GAAGvB,MAAM,CAACO,UAAU,CAAC,IAAI,CAAC;UAC7CgB,aAAa,CAACf,SAAS,CAACW,GAAG,EAAE,CAAC,EAAE,CAAC,EAAEnB,MAAM,CAACI,KAAK,EAAEJ,MAAM,CAACK,MAAM,CAAC,CAAC,CAAE;UAClE1C,WAAW,CAACD,QAAQ,CAAC,CAAC,CAAE;;UAExB;UACA,IAAIA,QAAQ,EAAE;YACZG,YAAY,CAAC,IAAI,CAAC;UACpB;QACF,CAAC;MAEH,CAAC,CAAC,OAAOsB,GAAG,EAAE;QACZD,OAAO,CAACD,KAAK,CAAC,yBAAyB,EAAEE,GAAG,CAAC;QAC7CxB,WAAW,CAAC,KAAK,CAAC,CAAC,CAAE;MACvB;IACF,CAAC,EAAE,YAAY,CAAC;EAClB,CAAC;EAEDT,SAAS,CAAC,MAAM;IACd,MAAMsE,QAAQ,GAAGC,WAAW,CAAC5B,YAAY,EAAE,IAAI,GAAG,EAAE,CAAC,CAAC,CAAE;IACxD,OAAO,MAAM6B,aAAa,CAACF,QAAQ,CAAC;EACtC,CAAC,EAAE,CAAC1D,cAAc,EAAEF,SAAS,EAAEI,cAAc,CAAC,CAAC;EAE/C,oBACET,OAAA;IAAAoE,QAAA,GAEG,CAAC3D,cAAc,iBACdT,OAAA;MAAQqE,OAAO,EAAEpC,cAAe;MAACqC,KAAK,EAAE;QAAEC,YAAY,EAAE;MAAO,CAAE;MAAAH,QAAA,EAAC;IAElE;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CACT,eAED3E,OAAA;MAAO4E,GAAG,EAAEjE,QAAS;MAAC2D,KAAK,EAAE;QAAEO,OAAO,EAAE;MAAO;IAAE;MAAAL,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,eACpD3E,OAAA;MAAQ4E,GAAG,EAAEhE,SAAU;MAACiC,KAAK,EAAC,KAAK;MAACC,MAAM,EAAC;IAAK;MAAA0B,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,EAElDxE,QAAQ,iBAAIH,OAAA;MAAGsE,KAAK,EAAE;QAAEQ,KAAK,EAAE,OAAO;QAAEC,SAAS,EAAE;MAAO,CAAE;MAAAX,QAAA,EAAC;IAAgB;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,EAGjFtE,SAAS,iBAAIL,OAAA;MAAGsE,KAAK,EAAE;QAAEQ,KAAK,EAAE,MAAM;QAAEC,SAAS,EAAE;MAAO,CAAE;MAAAX,QAAA,EAAC;IAAS;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACxE,CAAC;AAEV,CAAC;AAACzE,EAAA,CA3HID,UAAU;AAAA+E,EAAA,GAAV/E,UAAU;AA6HhB,eAAeA,UAAU;AAAC,IAAA+E,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}