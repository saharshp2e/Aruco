{"ast":null,"code":"var _jsxFileName = \"/home/user/Documents/Aruco_POC/aruco-detector/src/CameraFeed.js\",\n  _s = $RefreshSig$();\n// import React, { useEffect, useRef, useState } from 'react';\n// import axios from 'axios';\n\n// const CameraFeed = () => {\n//   const [detected, setDetected] = useState(false);\n//   const [completed, setCompleted] = useState(false);\n//   const [currentStep, setCurrentStep] = useState(0);  // Track the current step\n//   const [isTutorialStarted, setIsTutorialStarted] = useState(false); // Track whether tutorial has started\n//   const [isAudioPlaying, setIsAudioPlaying] = useState(false);\n//   const videoRef = useRef(null);\n//   const canvasRef = useRef(null);\n//   const audioRefs = useRef([\n//     new Audio('/voice1.mp3'), // Step 1: Introduction to sulfate test\n//     new Audio('/voice2.mp3'), // Step 2: Show distilled water\n//     new Audio('/voice3.mp3'), // Step 3: Show test tube 1\n//     new Audio('/voice4.mp3'),\n//     new Audio('/voice5.mp3'),\n//     new Audio('/voice6.mp3'),\n//     new Audio('/voice7.mp3'),\n//     new Audio('/voice8.mp3'),\n//     new Audio('/voice9.mp3'),\n//     new Audio('/voice10.mp3'),\n//     new Audio('/voice11.mp3'),\n//     new Audio('/voice12.mp3'),\n//     new Audio('/voice13.mp3'), // Step 13: Test completion message\n//   ]);\n\n//   // Start camera feed and process frames only when the tutorial is started\n//   useEffect(() => {\n//     if (isTutorialStarted) {\n//       const video = videoRef.current;\n\n//       // Web camera initialization logic\n//       navigator.mediaDevices.getUserMedia({ video: true })\n//         .then((stream) => {\n//           video.srcObject = stream;\n//           video.onloadedmetadata = () => {\n//             video.play();\n//           };\n//         })\n//         .catch(err => console.error(\"Error accessing webcam:\", err));\n\n//       // Clean up: stop the camera stream when component unmounts\n//       return () => {\n//         if (video.srcObject) {\n//           video.srcObject.getTracks().forEach(track => track.stop());\n//         }\n//       };\n//     }\n//   }, [isTutorialStarted]);  // Only run this effect when the tutorial starts\n\n//   const processFrame = async () => {\n//     if (!isTutorialStarted || completed) return;  // Stop processing if the tutorial hasn't started or test is complete\n\n//     const canvas = canvasRef.current;\n//     const context = canvas.getContext('2d');\n\n//     // Ensure video is ready and draw the video feed onto the canvas\n//     const video = videoRef.current;\n//     if (video.readyState === video.HAVE_ENOUGH_DATA) {\n//       context.drawImage(video, 0, 0, canvas.width, canvas.height);\n\n//       // Send frame to backend for ArUco detection\n//       canvas.toBlob(async (blob) => {\n//         const formData = new FormData();\n//         formData.append('image', blob, 'frame.jpg');\n//         try {\n//           const response = await axios.post('http://localhost:5000/detect', formData, { responseType: 'json' });\n//           // console.log(\"Response from backend:\", response.data);  // Log response\n\n//           const { detected, augmented_image, ids, currentStep } = response.data;  // Destructure response\n\n//           if (ids) {\n//               handleMarkerDetection(ids, currentStep);\n//             }\n\n//           // Clear the canvas before drawing the new image\n//           context.clearRect(0, 0, canvas.width, canvas.height);\n\n//           // Display processed frame (augmented) coming from backend\n//           const img = new Image();\n//           img.src = `data:image/jpeg;base64,${augmented_image}`;\n//           img.onload = () => {\n//             context.drawImage(img, 0, 0, canvas.width, canvas.height);\n//           };\n//         } catch (err) {\n//           console.error(\"Error processing frame:\", err);\n//         }\n//       }, 'image/jpeg');\n//     }\n//   };\n\n//   const handleMarkerDetection = (ids,currentStepFromBackend) => {\n//     if (completed) return;\n//     // console.log('inside handleMarkerDetection');\n//      // Stop if completed\n\n//         // For step 5, ensure both IDs 1 and 3 are present\n//     if (currentStep === 5 && ids.includes(1) && ids.includes(3)) {\n//       console.log('Step 5: Detected both Marker 1 and Marker 3');\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     if (currentStep === 6 && ids.includes(0) && ids.includes(1)) {\n//       console.log('Step 6: Detected both Marker 0 and Marker 1');\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 7: Detect marker ID=1 with alternating y-axis conditions\n//     if (currentStep === 7 && ids.includes(1) && !ids.includes(0)) {\n//       console.log('Step 7: Marker 1 detected, alternating y-axis required');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 8: Detect marker ID=1 with alternating y-axis conditions\n//     if (currentStep === 8 && ids.includes(1) && ids.includes(2)) {\n//       console.log('Step 8: Detected both Marker 1 and Marker 2');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 9: Detect marker ID=1 and marker ID=3\n//     if (currentStep === 9 && ids.includes(1) && ids.includes(3)) {\n//       console.log('Step 9: Detected both Marker 1 and Marker 3');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 10: Detect marker ID=1 and marker ID=4\n//     if (currentStep === 10 && ids.includes(1) && ids.includes(4)) {\n//       console.log('Step 10: Detected both Marker 1 and Marker 4');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     const expectedMarkerId = currentStep; // Expect the next marker ID\n//     // console.log('expectedMarkerId: '+expectedMarkerId+',currentSTep: '+currentStep)\n\n//     if (ids.includes(expectedMarkerId)) {\n//       console.log(`Step ${expectedMarkerId} verified with marker ID: ${expectedMarkerId}`);\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//     }\n//   };\n\n//   const playNextAudio = () => {\n//     if (currentStep + 2 >= audioRefs.current.length) return; // Prevent out-of-bounds\n\n//     const currentAudio = audioRefs.current[currentStep + 2];\n\n//     setIsAudioPlaying(true); // Set audio playing to true\n//     currentAudio.play().catch(err => console.error(\"Audio play error:\", err));\n\n//     currentAudio.onended = () => {\n//       setIsAudioPlaying(false); // Set audio playing to false after it finishes\n\n//       // Check if this is the last instructional step\n//       if (currentStep === audioRefs.current.length - 2) {\n//         setCompleted(true);\n//         audioRefs.current[audioRefs.current.length - 1].play().catch(err => console.error(\"Audio play error:\", err)); // Play completion audio\n//       }\n//     };\n//   };\n\n//   // Trigger the frame processing when the tutorial starts\n//   useEffect(() => {\n//     if (isTutorialStarted) {\n//       const interval = setInterval(processFrame, 1000 / 10);  // 10 FPS\n//       return () => clearInterval(interval);\n//     }\n//   }, [isTutorialStarted, currentStep]);\n\n//   const startTutorial = () => {\n//     setIsTutorialStarted(true);\n//     audioRefs.current[0].play().catch(err => console.error(\"Audio play error:\", err));\n//     audioRefs.current[0].onended = () => {\n//       audioRefs.current[1].play().catch(err => console.error(\"Audio play error:\", err));\n//     };\n//     setCurrentStep(0);\n//   };\n\n//   return (\n//     <div>\n//       {!isTutorialStarted && (\n//         <button onClick={startTutorial}>Start Tutorial</button>\n//       )}\n//       {isTutorialStarted && (\n//         <div>\n//           <video ref={videoRef} style={{ display: 'none' }} />\n//           <canvas ref={canvasRef} width=\"640\" height=\"480\" style={{ border: '1px solid black' }} />\n//           {completed && <p style={{ color: 'blue', marginTop: '10px' }}>Sulfate Ion Test Completed</p>}\n//         </div>\n//       )}\n//     </div>\n//   );\n// };\n\n// export default CameraFeed;\n\nimport React, { useEffect, useRef, useState } from 'react';\nimport axios from 'axios';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst CameraFeed = () => {\n  _s();\n  const [detected, setDetected] = useState(false);\n  const [completed, setCompleted] = useState(false);\n  const [currentStep, setCurrentStep] = useState(0); // Track the current step\n  const [isTutorialStarted, setIsTutorialStarted] = useState(false); // Track whether tutorial has started\n  const [isAudioPlaying, setIsAudioPlaying] = useState(false); // Track if audio is playing\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  const audioRefs = useRef([new Audio('/voice1.mp3'),\n  // Step 1: Introduction to sulfate test\n  new Audio('/voice2.mp3'),\n  // Step 2: Show distilled water\n  new Audio('/voice3.mp3'),\n  // Step 3: Show test tube 1\n  new Audio('/voice4.mp3'), new Audio('/voice5.mp3'), new Audio('/voice6.mp3'), new Audio('/voice7.mp3'), new Audio('/voice8.mp3'), new Audio('/voice9.mp3'), new Audio('/voice10.mp3'), new Audio('/voice11.mp3'), new Audio('/voice12.mp3'),\n  // Add the rest of the steps here\n  new Audio('/voice13.mp3') // Step 13: Test completion message\n  ]);\n\n  // Start camera feed and process frames only when the tutorial is started\n  useEffect(() => {\n    if (isTutorialStarted) {\n      const video = videoRef.current;\n\n      // Web camera initialization logic\n      navigator.mediaDevices.getUserMedia({\n        video: true\n      }).then(stream => {\n        video.srcObject = stream;\n        video.onloadedmetadata = () => {\n          video.play();\n        };\n      }).catch(err => console.error(\"Error accessing webcam:\", err));\n\n      // Clean up: stop the camera stream when component unmounts\n      return () => {\n        if (video.srcObject) {\n          video.srcObject.getTracks().forEach(track => track.stop());\n        }\n      };\n    }\n  }, [isTutorialStarted]); // Only run this effect when the tutorial starts\n\n  const processFrame = async () => {\n    if (!isTutorialStarted || completed || isAudioPlaying) return; // Stop processing if tutorial hasn't started, is completed, or audio is playing\n\n    const canvas = canvasRef.current;\n    const context = canvas.getContext('2d');\n\n    // Ensure video is ready and draw the video feed onto the canvas\n    const video = videoRef.current;\n    if (video.readyState === video.HAVE_ENOUGH_DATA) {\n      context.drawImage(video, 0, 0, canvas.width, canvas.height);\n\n      // Send frame to backend for ArUco detection\n      canvas.toBlob(async blob => {\n        const formData = new FormData();\n        formData.append('image', blob, 'frame.jpg');\n        try {\n          const response = await axios.post('http://localhost:5000/detect', formData, {\n            responseType: 'json'\n          });\n          // console.log(\"Response from backend:\", response.data);  // Log response\n\n          const {\n            detected,\n            augmented_image,\n            ids,\n            currentStep\n          } = response.data; // Destructure response\n\n          if (ids) {\n            handleMarkerDetection(ids, currentStep);\n          }\n\n          // Clear the canvas before drawing the new image\n          context.clearRect(0, 0, canvas.width, canvas.height);\n\n          // Display processed frame (augmented) coming from backend\n          const img = new Image();\n          img.src = `data:image/jpeg;base64,${augmented_image}`;\n          img.onload = () => {\n            context.drawImage(img, 0, 0, canvas.width, canvas.height);\n          };\n        } catch (err) {\n          console.error(\"Error processing frame:\", err);\n        }\n      }, 'image/jpeg');\n    }\n  };\n  const handleMarkerDetection = (ids, currentStepFromBackend) => {\n    if (completed) return;\n    // Stop if completed\n\n    // For step 5, ensure both IDs 1 and 3 are present\n    if (currentStep === 5 && ids.includes(1) && ids.includes(3)) {\n      console.log('Step 5: Detected both Marker 1 and Marker 3');\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n    if (currentStep === 6 && ids.includes(0) && ids.includes(1)) {\n      console.log('Step 6: Detected both Marker 0 and Marker 1');\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n\n    // Step 7: Detect marker ID=1 with alternating y-axis conditions\n    if (currentStep === 7 && ids.includes(1) && !ids.includes(0)) {\n      console.log('Step 7: Marker 1 detected, alternating y-axis required');\n      // Assume the backend sends this information via the currentStepFromBackend\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n\n    // Step 8: Detect marker ID=1 with alternating y-axis conditions\n    if (currentStep === 8 && ids.includes(1) && ids.includes(2)) {\n      console.log('Step 8: Detected both Marker 1 and Marker 2');\n      // Assume the backend sends this information via the currentStepFromBackend\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n\n    // Step 9: Detect marker ID=1 and marker ID=3\n    if (currentStep === 9 && ids.includes(1) && ids.includes(3)) {\n      console.log('Step 9: Detected both Marker 1 and Marker 3');\n      // Assume the backend sends this information via the currentStepFromBackend\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n\n    // Step 10: Detect marker ID=1 and marker ID=4\n    if (currentStep === 10 && ids.includes(1) && ids.includes(4)) {\n      console.log('Step 10: Detected both Marker 1 and Marker 4');\n      // Assume the backend sends this information via the currentStepFromBackend\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n    const expectedMarkerId = currentStep; // Expect the next marker ID\n\n    if (ids.includes(expectedMarkerId)) {\n      console.log(`Step ${expectedMarkerId} verified with marker ID: ${expectedMarkerId}`);\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n    }\n  };\n  const playNextAudio = () => {\n    if (currentStep + 2 >= audioRefs.current.length) return; // Prevent out-of-bounds\n\n    const currentAudio = audioRefs.current[currentStep + 2];\n    setIsAudioPlaying(true); // Set audio playing to true\n    currentAudio.play().catch(err => console.error(\"Audio play error:\", err));\n    currentAudio.onended = () => {\n      setIsAudioPlaying(false); // Set audio playing to false after it finishes\n\n      // Check if this is the last instructional step\n      if (currentStep === audioRefs.current.length - 2) {\n        setCompleted(true);\n        audioRefs.current[audioRefs.current.length - 1].play().catch(err => console.error(\"Audio play error:\", err)); // Play completion audio\n      }\n    };\n  };\n\n  // Trigger the frame processing when the tutorial starts\n  useEffect(() => {\n    if (isTutorialStarted) {\n      const interval = setInterval(processFrame, 1000 / 10); // 10 FPS\n      return () => clearInterval(interval);\n    }\n  }, [isTutorialStarted, currentStep, isAudioPlaying]); // Added isAudioPlaying to the dependency array\n\n  const startTutorial = () => {\n    setIsTutorialStarted(true);\n    audioRefs.current[0].play().catch(err => console.error(\"Audio play error:\", err));\n    audioRefs.current[0].onended = () => {\n      audioRefs.current[1].play().catch(err => console.error(\"Audio play error:\", err));\n    };\n    setCurrentStep(0);\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [!isTutorialStarted && /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: startTutorial,\n      children: \"Start Tutorial\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 426,\n      columnNumber: 9\n    }, this), isTutorialStarted && /*#__PURE__*/_jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"video\", {\n        ref: videoRef,\n        style: {\n          display: 'none'\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 430,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n        ref: canvasRef,\n        width: \"640\",\n        height: \"480\",\n        style: {\n          border: '1px solid black'\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 431,\n        columnNumber: 11\n      }, this), completed && /*#__PURE__*/_jsxDEV(\"p\", {\n        style: {\n          color: 'blue',\n          marginTop: '10px'\n        },\n        children: \"Sulfate Ion Test Completed\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 432,\n        columnNumber: 25\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 429,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 424,\n    columnNumber: 5\n  }, this);\n};\n_s(CameraFeed, \"myaZvWL/OYsxI1hztIaULrls4e0=\");\n_c = CameraFeed;\nexport default CameraFeed;\nvar _c;\n$RefreshReg$(_c, \"CameraFeed\");","map":{"version":3,"names":["React","useEffect","useRef","useState","axios","jsxDEV","_jsxDEV","CameraFeed","_s","detected","setDetected","completed","setCompleted","currentStep","setCurrentStep","isTutorialStarted","setIsTutorialStarted","isAudioPlaying","setIsAudioPlaying","videoRef","canvasRef","audioRefs","Audio","video","current","navigator","mediaDevices","getUserMedia","then","stream","srcObject","onloadedmetadata","play","catch","err","console","error","getTracks","forEach","track","stop","processFrame","canvas","context","getContext","readyState","HAVE_ENOUGH_DATA","drawImage","width","height","toBlob","blob","formData","FormData","append","response","post","responseType","augmented_image","ids","data","handleMarkerDetection","clearRect","img","Image","src","onload","currentStepFromBackend","includes","log","playNextAudio","expectedMarkerId","length","currentAudio","onended","interval","setInterval","clearInterval","startTutorial","children","onClick","fileName","_jsxFileName","lineNumber","columnNumber","ref","style","display","border","color","marginTop","_c","$RefreshReg$"],"sources":["/home/user/Documents/Aruco_POC/aruco-detector/src/CameraFeed.js"],"sourcesContent":["\n// import React, { useEffect, useRef, useState } from 'react';\n// import axios from 'axios';\n\n// const CameraFeed = () => {\n//   const [detected, setDetected] = useState(false);\n//   const [completed, setCompleted] = useState(false);\n//   const [currentStep, setCurrentStep] = useState(0);  // Track the current step\n//   const [isTutorialStarted, setIsTutorialStarted] = useState(false); // Track whether tutorial has started\n//   const [isAudioPlaying, setIsAudioPlaying] = useState(false);\n//   const videoRef = useRef(null);\n//   const canvasRef = useRef(null);\n//   const audioRefs = useRef([\n//     new Audio('/voice1.mp3'), // Step 1: Introduction to sulfate test\n//     new Audio('/voice2.mp3'), // Step 2: Show distilled water\n//     new Audio('/voice3.mp3'), // Step 3: Show test tube 1\n//     new Audio('/voice4.mp3'),\n//     new Audio('/voice5.mp3'),\n//     new Audio('/voice6.mp3'),\n//     new Audio('/voice7.mp3'),\n//     new Audio('/voice8.mp3'),\n//     new Audio('/voice9.mp3'),\n//     new Audio('/voice10.mp3'),\n//     new Audio('/voice11.mp3'),\n//     new Audio('/voice12.mp3'),\n//     new Audio('/voice13.mp3'), // Step 13: Test completion message\n//   ]);\n\n//   // Start camera feed and process frames only when the tutorial is started\n//   useEffect(() => {\n//     if (isTutorialStarted) {\n//       const video = videoRef.current;\n\n//       // Web camera initialization logic\n//       navigator.mediaDevices.getUserMedia({ video: true })\n//         .then((stream) => {\n//           video.srcObject = stream;\n//           video.onloadedmetadata = () => {\n//             video.play();\n//           };\n//         })\n//         .catch(err => console.error(\"Error accessing webcam:\", err));\n\n//       // Clean up: stop the camera stream when component unmounts\n//       return () => {\n//         if (video.srcObject) {\n//           video.srcObject.getTracks().forEach(track => track.stop());\n//         }\n//       };\n//     }\n//   }, [isTutorialStarted]);  // Only run this effect when the tutorial starts\n\n//   const processFrame = async () => {\n//     if (!isTutorialStarted || completed) return;  // Stop processing if the tutorial hasn't started or test is complete\n  \n//     const canvas = canvasRef.current;\n//     const context = canvas.getContext('2d');\n    \n//     // Ensure video is ready and draw the video feed onto the canvas\n//     const video = videoRef.current;\n//     if (video.readyState === video.HAVE_ENOUGH_DATA) {\n//       context.drawImage(video, 0, 0, canvas.width, canvas.height);\n  \n//       // Send frame to backend for ArUco detection\n//       canvas.toBlob(async (blob) => {\n//         const formData = new FormData();\n//         formData.append('image', blob, 'frame.jpg');\n//         try {\n//           const response = await axios.post('http://localhost:5000/detect', formData, { responseType: 'json' });\n//           // console.log(\"Response from backend:\", response.data);  // Log response\n  \n//           const { detected, augmented_image, ids, currentStep } = response.data;  // Destructure response\n          \n//           if (ids) {\n//               handleMarkerDetection(ids, currentStep);\n//             }\n\n//           // Clear the canvas before drawing the new image\n//           context.clearRect(0, 0, canvas.width, canvas.height);\n  \n//           // Display processed frame (augmented) coming from backend\n//           const img = new Image();\n//           img.src = `data:image/jpeg;base64,${augmented_image}`;\n//           img.onload = () => {\n//             context.drawImage(img, 0, 0, canvas.width, canvas.height);\n//           };\n//         } catch (err) {\n//           console.error(\"Error processing frame:\", err);\n//         }\n//       }, 'image/jpeg');\n//     }\n//   };\n\n\n\n//   const handleMarkerDetection = (ids,currentStepFromBackend) => {\n//     if (completed) return;\n//     // console.log('inside handleMarkerDetection');\n//      // Stop if completed\n\n\n//         // For step 5, ensure both IDs 1 and 3 are present\n//     if (currentStep === 5 && ids.includes(1) && ids.includes(3)) {\n//       console.log('Step 5: Detected both Marker 1 and Marker 3');\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     if (currentStep === 6 && ids.includes(0) && ids.includes(1)) {\n//       console.log('Step 6: Detected both Marker 0 and Marker 1');\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 7: Detect marker ID=1 with alternating y-axis conditions\n//     if (currentStep === 7 && ids.includes(1) && !ids.includes(0)) {\n//       console.log('Step 7: Marker 1 detected, alternating y-axis required');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 8: Detect marker ID=1 with alternating y-axis conditions\n//     if (currentStep === 8 && ids.includes(1) && ids.includes(2)) {\n//       console.log('Step 8: Detected both Marker 1 and Marker 2');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 9: Detect marker ID=1 and marker ID=3\n//     if (currentStep === 9 && ids.includes(1) && ids.includes(3)) {\n//       console.log('Step 9: Detected both Marker 1 and Marker 3');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     // Step 10: Detect marker ID=1 and marker ID=4\n//     if (currentStep === 10 && ids.includes(1) && ids.includes(4)) {\n//       console.log('Step 10: Detected both Marker 1 and Marker 4');\n//       // Assume the backend sends this information via the currentStepFromBackend\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//       return;\n//     }\n\n//     const expectedMarkerId = currentStep; // Expect the next marker ID\n//     // console.log('expectedMarkerId: '+expectedMarkerId+',currentSTep: '+currentStep)\n\n//     if (ids.includes(expectedMarkerId)) {\n//       console.log(`Step ${expectedMarkerId} verified with marker ID: ${expectedMarkerId}`);\n//       setCurrentStep(currentStep + 1);\n//       playNextAudio();\n//     }\n//   };\n\n//   const playNextAudio = () => {\n//     if (currentStep + 2 >= audioRefs.current.length) return; // Prevent out-of-bounds\n    \n    \n//     const currentAudio = audioRefs.current[currentStep + 2];\n\n    \n//     setIsAudioPlaying(true); // Set audio playing to true\n//     currentAudio.play().catch(err => console.error(\"Audio play error:\", err));\n    \n//     currentAudio.onended = () => {\n//       setIsAudioPlaying(false); // Set audio playing to false after it finishes\n  \n//       // Check if this is the last instructional step\n//       if (currentStep === audioRefs.current.length - 2) {\n//         setCompleted(true);\n//         audioRefs.current[audioRefs.current.length - 1].play().catch(err => console.error(\"Audio play error:\", err)); // Play completion audio\n//       }\n//     };\n//   };\n  \n  \n\n  \n//   // Trigger the frame processing when the tutorial starts\n//   useEffect(() => {\n//     if (isTutorialStarted) {\n//       const interval = setInterval(processFrame, 1000 / 10);  // 10 FPS\n//       return () => clearInterval(interval);\n//     }\n//   }, [isTutorialStarted, currentStep]);\n\n\n//   const startTutorial = () => {\n//     setIsTutorialStarted(true);\n//     audioRefs.current[0].play().catch(err => console.error(\"Audio play error:\", err));\n//     audioRefs.current[0].onended = () => {\n//       audioRefs.current[1].play().catch(err => console.error(\"Audio play error:\", err));\n//     };\n//     setCurrentStep(0);\n//   };\n  \n\n//   return (\n//     <div>\n//       {!isTutorialStarted && (\n//         <button onClick={startTutorial}>Start Tutorial</button>\n//       )}\n//       {isTutorialStarted && (\n//         <div>\n//           <video ref={videoRef} style={{ display: 'none' }} />\n//           <canvas ref={canvasRef} width=\"640\" height=\"480\" style={{ border: '1px solid black' }} />\n//           {completed && <p style={{ color: 'blue', marginTop: '10px' }}>Sulfate Ion Test Completed</p>}\n//         </div>\n//       )}\n//     </div>\n//   );\n// };\n\n// export default CameraFeed;\n\n\n\n\n\n\n\nimport React, { useEffect, useRef, useState } from 'react';\nimport axios from 'axios';\n\nconst CameraFeed = () => {\n  const [detected, setDetected] = useState(false);\n  const [completed, setCompleted] = useState(false);\n  const [currentStep, setCurrentStep] = useState(0); // Track the current step\n  const [isTutorialStarted, setIsTutorialStarted] = useState(false); // Track whether tutorial has started\n  const [isAudioPlaying, setIsAudioPlaying] = useState(false); // Track if audio is playing\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  const audioRefs = useRef([\n    new Audio('/voice1.mp3'), // Step 1: Introduction to sulfate test\n    new Audio('/voice2.mp3'), // Step 2: Show distilled water\n    new Audio('/voice3.mp3'), // Step 3: Show test tube 1\n    new Audio('/voice4.mp3'),\n    new Audio('/voice5.mp3'),\n    new Audio('/voice6.mp3'),\n    new Audio('/voice7.mp3'),\n    new Audio('/voice8.mp3'),\n    new Audio('/voice9.mp3'),\n    new Audio('/voice10.mp3'),\n    new Audio('/voice11.mp3'),\n    new Audio('/voice12.mp3'),\n    // Add the rest of the steps here\n    new Audio('/voice13.mp3'), // Step 13: Test completion message\n  ]);\n\n  // Start camera feed and process frames only when the tutorial is started\n  useEffect(() => {\n    if (isTutorialStarted) {\n      const video = videoRef.current;\n\n      // Web camera initialization logic\n      navigator.mediaDevices.getUserMedia({ video: true })\n        .then((stream) => {\n          video.srcObject = stream;\n          video.onloadedmetadata = () => {\n            video.play();\n          };\n        })\n        .catch(err => console.error(\"Error accessing webcam:\", err));\n\n      // Clean up: stop the camera stream when component unmounts\n      return () => {\n        if (video.srcObject) {\n          video.srcObject.getTracks().forEach(track => track.stop());\n        }\n      };\n    }\n  }, [isTutorialStarted]); // Only run this effect when the tutorial starts\n\n  const processFrame = async () => {\n    if (!isTutorialStarted || completed || isAudioPlaying) return; // Stop processing if tutorial hasn't started, is completed, or audio is playing\n\n    const canvas = canvasRef.current;\n    const context = canvas.getContext('2d');\n\n    // Ensure video is ready and draw the video feed onto the canvas\n    const video = videoRef.current;\n    if (video.readyState === video.HAVE_ENOUGH_DATA) {\n      context.drawImage(video, 0, 0, canvas.width, canvas.height);\n\n      // Send frame to backend for ArUco detection\n      canvas.toBlob(async (blob) => {\n        const formData = new FormData();\n        formData.append('image', blob, 'frame.jpg');\n        try {\n          const response = await axios.post('http://localhost:5000/detect', formData, { responseType: 'json' });\n          // console.log(\"Response from backend:\", response.data);  // Log response\n\n          const { detected, augmented_image, ids, currentStep } = response.data; // Destructure response\n\n          if (ids) {\n            handleMarkerDetection(ids, currentStep);\n          }\n\n          // Clear the canvas before drawing the new image\n          context.clearRect(0, 0, canvas.width, canvas.height);\n\n          // Display processed frame (augmented) coming from backend\n          const img = new Image();\n          img.src = `data:image/jpeg;base64,${augmented_image}`;\n          img.onload = () => {\n            context.drawImage(img, 0, 0, canvas.width, canvas.height);\n          };\n        } catch (err) {\n          console.error(\"Error processing frame:\", err);\n        }\n      }, 'image/jpeg');\n    }\n  };\n\n  const handleMarkerDetection = (ids, currentStepFromBackend) => {\n    if (completed) return;\n    // Stop if completed\n\n    // For step 5, ensure both IDs 1 and 3 are present\n    if (currentStep === 5 && ids.includes(1) && ids.includes(3)) {\n      console.log('Step 5: Detected both Marker 1 and Marker 3');\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n\n    if (currentStep === 6 && ids.includes(0) && ids.includes(1)) {\n      console.log('Step 6: Detected both Marker 0 and Marker 1');\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n\n    // Step 7: Detect marker ID=1 with alternating y-axis conditions\n    if (currentStep === 7 && ids.includes(1) && !ids.includes(0)) {\n      console.log('Step 7: Marker 1 detected, alternating y-axis required');\n      // Assume the backend sends this information via the currentStepFromBackend\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n\n    // Step 8: Detect marker ID=1 with alternating y-axis conditions\n    if (currentStep === 8 && ids.includes(1) && ids.includes(2)) {\n      console.log('Step 8: Detected both Marker 1 and Marker 2');\n      // Assume the backend sends this information via the currentStepFromBackend\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n\n    // Step 9: Detect marker ID=1 and marker ID=3\n    if (currentStep === 9 && ids.includes(1) && ids.includes(3)) {\n      console.log('Step 9: Detected both Marker 1 and Marker 3');\n      // Assume the backend sends this information via the currentStepFromBackend\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n\n    // Step 10: Detect marker ID=1 and marker ID=4\n    if (currentStep === 10 && ids.includes(1) && ids.includes(4)) {\n      console.log('Step 10: Detected both Marker 1 and Marker 4');\n      // Assume the backend sends this information via the currentStepFromBackend\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n      return;\n    }\n\n    const expectedMarkerId = currentStep; // Expect the next marker ID\n\n    if (ids.includes(expectedMarkerId)) {\n      console.log(`Step ${expectedMarkerId} verified with marker ID: ${expectedMarkerId}`);\n      setCurrentStep(currentStep + 1);\n      playNextAudio();\n    }\n  };\n\n  const playNextAudio = () => {\n    if (currentStep + 2 >= audioRefs.current.length) return; // Prevent out-of-bounds\n\n    const currentAudio = audioRefs.current[currentStep + 2];\n\n    setIsAudioPlaying(true); // Set audio playing to true\n    currentAudio.play().catch(err => console.error(\"Audio play error:\", err));\n\n    currentAudio.onended = () => {\n      setIsAudioPlaying(false); // Set audio playing to false after it finishes\n\n      // Check if this is the last instructional step\n      if (currentStep === audioRefs.current.length - 2) {\n        setCompleted(true);\n        audioRefs.current[audioRefs.current.length - 1].play().catch(err => console.error(\"Audio play error:\", err)); // Play completion audio\n      }\n    };\n  };\n\n  // Trigger the frame processing when the tutorial starts\n  useEffect(() => {\n    if (isTutorialStarted) {\n      const interval = setInterval(processFrame, 1000 / 10); // 10 FPS\n      return () => clearInterval(interval);\n    }\n  }, [isTutorialStarted, currentStep, isAudioPlaying]); // Added isAudioPlaying to the dependency array\n\n  const startTutorial = () => {\n    setIsTutorialStarted(true);\n    audioRefs.current[0].play().catch(err => console.error(\"Audio play error:\", err));\n    audioRefs.current[0].onended = () => {\n      audioRefs.current[1].play().catch(err => console.error(\"Audio play error:\", err));\n    };\n    setCurrentStep(0);\n  };\n\n  return (\n    <div>\n      {!isTutorialStarted && (\n        <button onClick={startTutorial}>Start Tutorial</button>\n      )}\n      {isTutorialStarted && (\n        <div>\n          <video ref={videoRef} style={{ display: 'none' }} />\n          <canvas ref={canvasRef} width=\"640\" height=\"480\" style={{ border: '1px solid black' }} />\n          {completed && <p style={{ color: 'blue', marginTop: '10px' }}>Sulfate Ion Test Completed</p>}\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default CameraFeed;\n"],"mappings":";;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAIA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAGA;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAQA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,MAAM,EAAEC,QAAQ,QAAQ,OAAO;AAC1D,OAAOC,KAAK,MAAM,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE1B,MAAMC,UAAU,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACvB,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGP,QAAQ,CAAC,KAAK,CAAC;EAC/C,MAAM,CAACQ,SAAS,EAAEC,YAAY,CAAC,GAAGT,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAACU,WAAW,EAAEC,cAAc,CAAC,GAAGX,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;EACnD,MAAM,CAACY,iBAAiB,EAAEC,oBAAoB,CAAC,GAAGb,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC;EACnE,MAAM,CAACc,cAAc,EAAEC,iBAAiB,CAAC,GAAGf,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC;EAC7D,MAAMgB,QAAQ,GAAGjB,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMkB,SAAS,GAAGlB,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMmB,SAAS,GAAGnB,MAAM,CAAC,CACvB,IAAIoB,KAAK,CAAC,aAAa,CAAC;EAAE;EAC1B,IAAIA,KAAK,CAAC,aAAa,CAAC;EAAE;EAC1B,IAAIA,KAAK,CAAC,aAAa,CAAC;EAAE;EAC1B,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,aAAa,CAAC,EACxB,IAAIA,KAAK,CAAC,cAAc,CAAC,EACzB,IAAIA,KAAK,CAAC,cAAc,CAAC,EACzB,IAAIA,KAAK,CAAC,cAAc,CAAC;EACzB;EACA,IAAIA,KAAK,CAAC,cAAc,CAAC,CAAE;EAAA,CAC5B,CAAC;;EAEF;EACArB,SAAS,CAAC,MAAM;IACd,IAAIc,iBAAiB,EAAE;MACrB,MAAMQ,KAAK,GAAGJ,QAAQ,CAACK,OAAO;;MAE9B;MACAC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAAEJ,KAAK,EAAE;MAAK,CAAC,CAAC,CACjDK,IAAI,CAAEC,MAAM,IAAK;QAChBN,KAAK,CAACO,SAAS,GAAGD,MAAM;QACxBN,KAAK,CAACQ,gBAAgB,GAAG,MAAM;UAC7BR,KAAK,CAACS,IAAI,CAAC,CAAC;QACd,CAAC;MACH,CAAC,CAAC,CACDC,KAAK,CAACC,GAAG,IAAIC,OAAO,CAACC,KAAK,CAAC,yBAAyB,EAAEF,GAAG,CAAC,CAAC;;MAE9D;MACA,OAAO,MAAM;QACX,IAAIX,KAAK,CAACO,SAAS,EAAE;UACnBP,KAAK,CAACO,SAAS,CAACO,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;QAC5D;MACF,CAAC;IACH;EACF,CAAC,EAAE,CAACzB,iBAAiB,CAAC,CAAC,CAAC,CAAC;;EAEzB,MAAM0B,YAAY,GAAG,MAAAA,CAAA,KAAY;IAC/B,IAAI,CAAC1B,iBAAiB,IAAIJ,SAAS,IAAIM,cAAc,EAAE,OAAO,CAAC;;IAE/D,MAAMyB,MAAM,GAAGtB,SAAS,CAACI,OAAO;IAChC,MAAMmB,OAAO,GAAGD,MAAM,CAACE,UAAU,CAAC,IAAI,CAAC;;IAEvC;IACA,MAAMrB,KAAK,GAAGJ,QAAQ,CAACK,OAAO;IAC9B,IAAID,KAAK,CAACsB,UAAU,KAAKtB,KAAK,CAACuB,gBAAgB,EAAE;MAC/CH,OAAO,CAACI,SAAS,CAACxB,KAAK,EAAE,CAAC,EAAE,CAAC,EAAEmB,MAAM,CAACM,KAAK,EAAEN,MAAM,CAACO,MAAM,CAAC;;MAE3D;MACAP,MAAM,CAACQ,MAAM,CAAC,MAAOC,IAAI,IAAK;QAC5B,MAAMC,QAAQ,GAAG,IAAIC,QAAQ,CAAC,CAAC;QAC/BD,QAAQ,CAACE,MAAM,CAAC,OAAO,EAAEH,IAAI,EAAE,WAAW,CAAC;QAC3C,IAAI;UACF,MAAMI,QAAQ,GAAG,MAAMnD,KAAK,CAACoD,IAAI,CAAC,8BAA8B,EAAEJ,QAAQ,EAAE;YAAEK,YAAY,EAAE;UAAO,CAAC,CAAC;UACrG;;UAEA,MAAM;YAAEhD,QAAQ;YAAEiD,eAAe;YAAEC,GAAG;YAAE9C;UAAY,CAAC,GAAG0C,QAAQ,CAACK,IAAI,CAAC,CAAC;;UAEvE,IAAID,GAAG,EAAE;YACPE,qBAAqB,CAACF,GAAG,EAAE9C,WAAW,CAAC;UACzC;;UAEA;UACA8B,OAAO,CAACmB,SAAS,CAAC,CAAC,EAAE,CAAC,EAAEpB,MAAM,CAACM,KAAK,EAAEN,MAAM,CAACO,MAAM,CAAC;;UAEpD;UACA,MAAMc,GAAG,GAAG,IAAIC,KAAK,CAAC,CAAC;UACvBD,GAAG,CAACE,GAAG,GAAG,0BAA0BP,eAAe,EAAE;UACrDK,GAAG,CAACG,MAAM,GAAG,MAAM;YACjBvB,OAAO,CAACI,SAAS,CAACgB,GAAG,EAAE,CAAC,EAAE,CAAC,EAAErB,MAAM,CAACM,KAAK,EAAEN,MAAM,CAACO,MAAM,CAAC;UAC3D,CAAC;QACH,CAAC,CAAC,OAAOf,GAAG,EAAE;UACZC,OAAO,CAACC,KAAK,CAAC,yBAAyB,EAAEF,GAAG,CAAC;QAC/C;MACF,CAAC,EAAE,YAAY,CAAC;IAClB;EACF,CAAC;EAED,MAAM2B,qBAAqB,GAAGA,CAACF,GAAG,EAAEQ,sBAAsB,KAAK;IAC7D,IAAIxD,SAAS,EAAE;IACf;;IAEA;IACA,IAAIE,WAAW,KAAK,CAAC,IAAI8C,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,IAAIT,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,EAAE;MAC3DjC,OAAO,CAACkC,GAAG,CAAC,6CAA6C,CAAC;MAC1DvD,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;MAC/ByD,aAAa,CAAC,CAAC;MACf;IACF;IAEA,IAAIzD,WAAW,KAAK,CAAC,IAAI8C,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,IAAIT,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,EAAE;MAC3DjC,OAAO,CAACkC,GAAG,CAAC,6CAA6C,CAAC;MAC1DvD,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;MAC/ByD,aAAa,CAAC,CAAC;MACf;IACF;;IAEA;IACA,IAAIzD,WAAW,KAAK,CAAC,IAAI8C,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,IAAI,CAACT,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,EAAE;MAC5DjC,OAAO,CAACkC,GAAG,CAAC,wDAAwD,CAAC;MACrE;MACAvD,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;MAC/ByD,aAAa,CAAC,CAAC;MACf;IACF;;IAEA;IACA,IAAIzD,WAAW,KAAK,CAAC,IAAI8C,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,IAAIT,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,EAAE;MAC3DjC,OAAO,CAACkC,GAAG,CAAC,6CAA6C,CAAC;MAC1D;MACAvD,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;MAC/ByD,aAAa,CAAC,CAAC;MACf;IACF;;IAEA;IACA,IAAIzD,WAAW,KAAK,CAAC,IAAI8C,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,IAAIT,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,EAAE;MAC3DjC,OAAO,CAACkC,GAAG,CAAC,6CAA6C,CAAC;MAC1D;MACAvD,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;MAC/ByD,aAAa,CAAC,CAAC;MACf;IACF;;IAEA;IACA,IAAIzD,WAAW,KAAK,EAAE,IAAI8C,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,IAAIT,GAAG,CAACS,QAAQ,CAAC,CAAC,CAAC,EAAE;MAC5DjC,OAAO,CAACkC,GAAG,CAAC,8CAA8C,CAAC;MAC3D;MACAvD,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;MAC/ByD,aAAa,CAAC,CAAC;MACf;IACF;IAEA,MAAMC,gBAAgB,GAAG1D,WAAW,CAAC,CAAC;;IAEtC,IAAI8C,GAAG,CAACS,QAAQ,CAACG,gBAAgB,CAAC,EAAE;MAClCpC,OAAO,CAACkC,GAAG,CAAC,QAAQE,gBAAgB,6BAA6BA,gBAAgB,EAAE,CAAC;MACpFzD,cAAc,CAACD,WAAW,GAAG,CAAC,CAAC;MAC/ByD,aAAa,CAAC,CAAC;IACjB;EACF,CAAC;EAED,MAAMA,aAAa,GAAGA,CAAA,KAAM;IAC1B,IAAIzD,WAAW,GAAG,CAAC,IAAIQ,SAAS,CAACG,OAAO,CAACgD,MAAM,EAAE,OAAO,CAAC;;IAEzD,MAAMC,YAAY,GAAGpD,SAAS,CAACG,OAAO,CAACX,WAAW,GAAG,CAAC,CAAC;IAEvDK,iBAAiB,CAAC,IAAI,CAAC,CAAC,CAAC;IACzBuD,YAAY,CAACzC,IAAI,CAAC,CAAC,CAACC,KAAK,CAACC,GAAG,IAAIC,OAAO,CAACC,KAAK,CAAC,mBAAmB,EAAEF,GAAG,CAAC,CAAC;IAEzEuC,YAAY,CAACC,OAAO,GAAG,MAAM;MAC3BxD,iBAAiB,CAAC,KAAK,CAAC,CAAC,CAAC;;MAE1B;MACA,IAAIL,WAAW,KAAKQ,SAAS,CAACG,OAAO,CAACgD,MAAM,GAAG,CAAC,EAAE;QAChD5D,YAAY,CAAC,IAAI,CAAC;QAClBS,SAAS,CAACG,OAAO,CAACH,SAAS,CAACG,OAAO,CAACgD,MAAM,GAAG,CAAC,CAAC,CAACxC,IAAI,CAAC,CAAC,CAACC,KAAK,CAACC,GAAG,IAAIC,OAAO,CAACC,KAAK,CAAC,mBAAmB,EAAEF,GAAG,CAAC,CAAC,CAAC,CAAC;MAChH;IACF,CAAC;EACH,CAAC;;EAED;EACAjC,SAAS,CAAC,MAAM;IACd,IAAIc,iBAAiB,EAAE;MACrB,MAAM4D,QAAQ,GAAGC,WAAW,CAACnC,YAAY,EAAE,IAAI,GAAG,EAAE,CAAC,CAAC,CAAC;MACvD,OAAO,MAAMoC,aAAa,CAACF,QAAQ,CAAC;IACtC;EACF,CAAC,EAAE,CAAC5D,iBAAiB,EAAEF,WAAW,EAAEI,cAAc,CAAC,CAAC,CAAC,CAAC;;EAEtD,MAAM6D,aAAa,GAAGA,CAAA,KAAM;IAC1B9D,oBAAoB,CAAC,IAAI,CAAC;IAC1BK,SAAS,CAACG,OAAO,CAAC,CAAC,CAAC,CAACQ,IAAI,CAAC,CAAC,CAACC,KAAK,CAACC,GAAG,IAAIC,OAAO,CAACC,KAAK,CAAC,mBAAmB,EAAEF,GAAG,CAAC,CAAC;IACjFb,SAAS,CAACG,OAAO,CAAC,CAAC,CAAC,CAACkD,OAAO,GAAG,MAAM;MACnCrD,SAAS,CAACG,OAAO,CAAC,CAAC,CAAC,CAACQ,IAAI,CAAC,CAAC,CAACC,KAAK,CAACC,GAAG,IAAIC,OAAO,CAACC,KAAK,CAAC,mBAAmB,EAAEF,GAAG,CAAC,CAAC;IACnF,CAAC;IACDpB,cAAc,CAAC,CAAC,CAAC;EACnB,CAAC;EAED,oBACER,OAAA;IAAAyE,QAAA,GACG,CAAChE,iBAAiB,iBACjBT,OAAA;MAAQ0E,OAAO,EAAEF,aAAc;MAAAC,QAAA,EAAC;IAAc;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CACvD,EACArE,iBAAiB,iBAChBT,OAAA;MAAAyE,QAAA,gBACEzE,OAAA;QAAO+E,GAAG,EAAElE,QAAS;QAACmE,KAAK,EAAE;UAAEC,OAAO,EAAE;QAAO;MAAE;QAAAN,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAE,CAAC,eACpD9E,OAAA;QAAQ+E,GAAG,EAAEjE,SAAU;QAAC4B,KAAK,EAAC,KAAK;QAACC,MAAM,EAAC,KAAK;QAACqC,KAAK,EAAE;UAAEE,MAAM,EAAE;QAAkB;MAAE;QAAAP,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAE,CAAC,EACxFzE,SAAS,iBAAIL,OAAA;QAAGgF,KAAK,EAAE;UAAEG,KAAK,EAAE,MAAM;UAAEC,SAAS,EAAE;QAAO,CAAE;QAAAX,QAAA,EAAC;MAA0B;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACzF,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV,CAAC;AAAC5E,EAAA,CA5MID,UAAU;AAAAoF,EAAA,GAAVpF,UAAU;AA8MhB,eAAeA,UAAU;AAAC,IAAAoF,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}